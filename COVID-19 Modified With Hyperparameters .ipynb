{"cells":[{"metadata":{"_uuid":"645a811e-a5e6-4126-bdb6-fe0bd1e81f02","_cell_guid":"af437f40-7f19-4668-b92a-28ab5f5e6c5f","trusted":true},"cell_type":"markdown","source":"# Introduction\nThis is taking https://www.kaggle.com/lisphilar's notebook and optimizing for parameters and trying things to validate the predictions. "},{"metadata":{},"cell_type":"markdown","source":"### Major update\n * 13Feb2020: SIR model\n * 15Feb2020: SIR-D model\n * 22Feb2020: SIR-F model\n * 23Feb2020: Changed the dataset from 2019_ncov_data.csv to covid_19_data.csv\n * 23Feb2020: $\\tau$ was fixed as \"1 day\" because the time format of ObservationDate is MM/DD/YYYY\n * 23Feb2020: SIR-F model with other countries\n * 23Feb2020: How to minimize the damage (Change of parameter, Vacctination)\n * 24Feb2020: Use $\\tau$ again\n * 01Mar2020: $\\tau$ definition was changed. $1\\leq \\tau \\mathrm{[hour]} \\leq 24$ $\\to$ $1\\leq \\tau \\mathrm{[min]} \\leq 1440$ \n * 01Mar2020: Added \"Test of hyperparameter optimization using example data\" in SIR model section\n * 02Mar2020: Analysis of Linelist (estimation of Effective contact/Recovery/Death rate using case reports)\n * 03Mar2020: Trend analysis\n * 03Mar2020: Update estimator error function; Exponential Weighted Moving Average (span=14days) of |observed - estimated|\n * 04Mar2020: \"Analysis of Linelist\" was moved to [EDA of linelist](https://www.kaggle.com/lisphilar/eda-of-linelist?scriptVersionId=29640733#Remarks)\n * 04Mar2020: Data in Hubei and China will be analysed in another notebook. Please refer to [Data in China with SIR model](https://www.kaggle.com/lisphilar/data-in-china-with-sir-model?scriptVersionId=29646940).\n * 06Mar2020: Random seed was fixed as 2019\n * 06Mar2020: Update estimator error function; Weighted Average of |Exponential Weighted Moving Average (span=14days) of observed - estimated|\n * 07Mar2020: Update estimator error function; Total population $\\times$ Wighted Average of |observed - estimated| with step number t\n * 07Mar2020: Priorities of variables in estimator error function was set as $(x, y, z, w) = (1, 10, 10, 1)$ in SIR-F model.\n * 09Mar2020: Update estimator error function; $(\\mathrm{Population})^2$ $\\times$ (Wighted Average of |observed - estimated|/[observed $\\times$ Population + 1] with step number t)\n * 09Mar2020: Priorities of variables in estimator error function were set as $(x, y, z, w) = (1, 10, 10, 2)$ in SIR-F model.\n * 11Mar2020: Update model.param_dict(); each parametor range was limited to 30%-70% quantiles of the estimated values ($\\frac{\\mathrm{d}z}{\\mathrm{d}t}\\left(\\frac{1}{y}\\right)$ for $\\sigma$) of training dataset.\n * 12Mar2020: Update model.param_dict(); each parameter range was limited to 5%-95% quantiles\n * 12Mar2020: Detailed scenario analysis. Thank you, Marco Ferrante!\n * 13Mar2020: Update model.param_dict(); each parameter range was limited to 0%-100% quantiles\n * 13Mar2020: Update \"Detailed scenario analysis\" > \"Real factors of effective contact rate $\\beta$\"\n * 14Mar2020: Update model.param_dict(); rho/sigma range was limited to 30%-70% quantiles of their estimated values\n * 14Mar2020: Applied trend analysis on country level data to use only a part of records for estimation\n * 14Mar2020: Recovered without confirmation was added to \"Real factors of effective contact rate $\\beta$\"\n * 14Mar2020: Resource of total population values was changed to [PopulationPyramid.net WORLD 2020](https://www.populationpyramid.net/world/2020/)\n * 15Mar2020: Merge \"How to minimize the damage (Change of parameter, Vacctination)\" with \"Scenario analysis\" section\n * 15Mar2020: Update Estimator, int to np.int. Thank you Enrico Papalini!\n * 15Mar2020: Update Estimator, some parameters can be fixed. Some of SIR parameters can be applied to SIR-F model.\n * 17Mar2020: The number of exposed cases and waiting cases\n * 17Mar2020: Update Scenario analysis\n * 18Mar2020: Scenario analysis in Italy\n * 19Mar2020: Estimation of new drugs effect in \"Scenario analysis in Italy\" section\n \n <!--* 10Mar2020: In Estimator.objective(), apply adjusted Exponential Moving Average (span=7days) on the training data-->\n \n <!--* 08Mar2020: ODE solver method was changed from RK45 to Radau (Implicit Runge-Kutta method of the Radau IIA family of order 5) because max value of $\\tau$ is 1440[min] and the number of iterations tends to small. The numerical simulation system seems stiff equation. Please refer to [scipy.integrate.solve_ivp guide](https://docs.scipy.org/doc/scipy/reference/generated/scipy.integrate.solve_ivp.html).-->"},{"metadata":{"_uuid":"4a1c505a-af19-4114-9013-4d0cd725fc6e","_cell_guid":"0c5341ac-2f8d-46bb-8749-fa8804155603","trusted":true},"cell_type":"code","source":"from datetime import datetime\ntime_format = \"%d%b%Y %H:%M\"\ndatetime.now().strftime(time_format)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e8837623-1d76-40e3-8710-af80d55cfc9c","_cell_guid":"3779540e-8e00-4811-a789-6107b0d51e0c","trusted":true},"cell_type":"markdown","source":"# Arrangement of dataset"},{"metadata":{},"cell_type":"markdown","source":"## Package"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"from datetime import timedelta\nfrom dateutil.relativedelta import relativedelta\nimport os\nfrom pprint import pprint\nimport warnings\nfrom fbprophet import Prophet\nfrom fbprophet.plot import add_changepoints_to_plot\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\nimport matplotlib\nfrom matplotlib.ticker import ScalarFormatter\n%matplotlib inline\nimport numpy as np\nimport optuna\noptuna.logging.disable_default_handler()\nimport pandas as pd\npd.plotting.register_matplotlib_converters()\nimport seaborn as sns\nfrom scipy.integrate import solve_ivp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"np.random.seed(2019)\nos.environ[\"PYTHONHASHSEED\"] = \"2019\"","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plt.style.use(\"seaborn-ticks\")\nplt.rcParams[\"xtick.direction\"] = \"in\"\nplt.rcParams[\"ytick.direction\"] = \"in\"\nplt.rcParams[\"font.size\"] = 11.0\nplt.rcParams[\"figure.figsize\"] = (9, 6)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Total population and population pyramid\n**Total population values and population pyramid data of each country in 2020 was retrieved in CSV format from [PopulationPyramid.net](https://www.populationpyramid.net/) licenced under [Creative Commons license CC BY 3.0](https://creativecommons.org/licenses/by/3.0/igo/).** Data was transformed for ease to use in this notebook."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"_age_bins = [\n    \"0-4\", \"5-9\", \"10-14\", \"15-19\", \"20-24\", \"25-29\",\n    \"30-34\", \"35-39\", \"40-44\", \"45-49\", \"50-54\", \"55-59\",\n    \"60-64\", \"65-69\", \"70-74\", \"75-79\", \"80-84\", \"85-89\",\n    \"90-94\", \"95-99\", \"100+\"\n]\n_pyramid_df = pd.DataFrame({\"Age_bin\": _age_bins})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Global (WORLD)\n_name = \"Global\"\n_male = [\n    349432556,\n    342927576,\n    331497486,\n    316642222,\n    308286775,\n    306059387,\n    309236984,\n    276447037,\n    249389688,\n    241232876,\n    222609691,\n    192215395,\n    157180267,\n    128939392,\n    87185982,\n    54754941,\n    33648953,\n    15756942,\n    5327866,\n    1077791,\n    124144\n]\n_female = [\n    328509234,\n    321511867,\n    309769906,\n    295553758,\n    289100903,\n    288632766,\n    296293748,\n    268371754,\n    244399176,\n    238133281,\n    223162982,\n    195633743,\n    164961323,\n    140704320,\n    101491347,\n    69026831,\n    48281201,\n    26429329,\n    11352182,\n    3055845,\n    449279\n]\n_pyramid_df[_name] = np.array(_male) + np.array(_female)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"_name = \"China\"\n_male = [\n    44456332,\n    46320144,\n    45349923,\n    44103122,\n    46273865,\n    51522843,\n    66443228,\n    51345507,\n    49289359,\n    61173349,\n    62348020,\n    49958045,\n    38917285,\n    36526788,\n    21425163,\n    12207276,\n    6883629,\n    2843084,\n    731228,\n    116377,\n    12773\n]\n_female = [\n    39476105,\n    40415039,\n    38912828,\n    38238737,\n    40884302,\n    46466160,\n    62295742,\n    48745948,\n    46984787,\n    58664268,\n    61097362,\n    48782446,\n    38596854,\n    37622978,\n    23524526,\n    14337340,\n    9297788,\n    4738693,\n    1573796,\n    358816,\n    61919\n]\n_pyramid_df[_name] = np.array(_male) + np.array(_female)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_pyramid_df[\"Except China\"] = _pyramid_df[\"Global\"] - _pyramid_df[\"China\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"_name = \"Japan\"\n_male = [\n    2453834,\n    2773482,\n    2856888,\n    2926787,\n    3075580,\n    3151556,\n    3475526,\n    3918085,\n    4307199,\n    5088697,\n    4364792,\n    3964557,\n    3733454,\n    4095950,\n    4312462,\n    3160764,\n    2209841,\n    1282793,\n    495632,\n    95394,\n    9772\n]\n_female = [\n    2324647,\n    2628006,\n    2707638,\n    2775858,\n    2921297,\n    2998892,\n    3314219,\n    3747586,\n    4161221,\n    4915957,\n    4293819,\n    3918347,\n    3762668,\n    4283163,\n    4814856,\n    3897293,\n    3129208,\n    2347551,\n    1290191,\n    422131,\n    68864\n]\n_pyramid_df[_name] = np.array(_male) + np.array(_female)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"_name = \"Italy\"\n_male = [\n    1197289,\n    1374731,\n    1470174,\n    1484455,\n    1526577,\n    1625230,\n    1702976,\n    1824273,\n    2092329,\n    2401070,\n    2420466,\n    2274884,\n    1903045,\n    1679600,\n    1586760,\n    1182323,\n    958360,\n    504059,\n    186608,\n    39461,\n    3055\n]\n_female = [\n    1127405,\n    1295570,\n    1387183,\n    1391636,\n    1415929,\n    1535700,\n    1662536,\n    1808649,\n    2096655,\n    2431950,\n    2487780,\n    2384062,\n    2050522,\n    1851695,\n    1805038,\n    1454787,\n    1344033,\n    893202,\n    453131,\n    133178,\n    13462\n]\n_pyramid_df[_name] = np.array(_male) + np.array(_female)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# South Korea (Republic of Korea)\n_name = \"South Korea\"\n_male = [\n    974300,\n    1158751,\n    1174844,\n    1289269,\n    1683129,\n    1870859,\n    1733487,\n    1974613,\n    2015813,\n    2186422,\n    2168485,\n    2082574,\n    1855904,\n    1287861,\n    929821,\n    664900,\n    403886,\n    160921,\n    41739,\n    7689,\n    587\n]\n_female = [\n    922711,\n    1098051,\n    1101938,\n    1187207,\n    1533115,\n    1629191,\n    1548938,\n    1822801,\n    1909121,\n    2107488,\n    2147031,\n    2078609,\n    1918662,\n    1391279,\n    1068270,\n    897655,\n    679943,\n    379182,\n    143170,\n    35207,\n    3760\n]\n_pyramid_df[_name] = np.array(_male) + np.array(_female)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"_name = \"Iran\"\n_male = [\n    3913297,\n    3566704,\n    3185825,\n    2829745,\n    2801162,\n    3382446,\n    4211840,\n    4120404,\n    3270956,\n    2608048,\n    2321587,\n    1826123,\n    1559797,\n    1128726,\n    709933,\n    471441,\n    306847,\n    162121,\n    27495,\n    3670,\n    238\n]\n_female = [\n    3724262,\n    3361593,\n    3032120,\n    2700238,\n    2755066,\n    3404233,\n    4254862,\n    4152339,\n    3220365,\n    2556247,\n    2296892,\n    1850729,\n    1572477,\n    1135905,\n    738068,\n    435165,\n    244765,\n    115360,\n    29181,\n    4400,\n    280\n]\n_pyramid_df[_name] = np.array(_male) + np.array(_female)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"_name = \"UK\"\n_male = [\n    2009363,\n    2108550,\n    2022370,\n    1880611,\n    2072674,\n    2275138,\n    2361054,\n    2279836,\n    2148253,\n    2128343,\n    2281421,\n    2232388,\n    1919839,\n    1647391,\n    1624635,\n    1137438,\n    766956,\n    438663,\n    169952,\n    34524,\n    3016\n]\n_female = [\n    1915127,\n    2011016,\n    1933970,\n    1805522,\n    2001966,\n    2208929,\n    2345774,\n    2308360,\n    2159877,\n    2167778,\n    2353119,\n    2306537,\n    1985177,\n    1734370,\n    1763853,\n    1304709,\n    969611,\n    638892,\n    320625,\n    95559,\n    12818\n]\n_pyramid_df[_name] = np.array(_male) + np.array(_female)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"_name = \"US\"\n_male = [\n    10055063,\n    10246393,\n    10777513,\n    10834321,\n    11322732,\n    12144455,\n    11702514,\n    10858871,\n    10118582,\n    9969099,\n    10319535,\n    10702065,\n    10049886,\n    8465274,\n    6645519,\n    4326986,\n    2805623,\n    1538659,\n    703131,\n    179003,\n    20792\n]\n_female = [\n    9621269,\n    9798759,\n    10311974,\n    10408587,\n    10936013,\n    11690875,\n    11349965,\n    10756920,\n    10176017,\n    10084699,\n    10258272,\n    10840205,\n    10619257,\n    9353753,\n    7709344,\n    5400748,\n    3655579,\n    2372445,\n    1348005,\n    447633,\n    76312\n]\n_pyramid_df[_name] = np.array(_male) + np.array(_female)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"\"\"\"\n_name = \"Template\"\n_male = [\n]\n_female = [\n]\n_pyramid_df[_name] = np.array(_male) + np.array(_female)\n\"\"\"\nNone","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"df = _pyramid_df.drop([\"Age_bin\"], axis=1).sum(axis=0)\npopulation_dict = df.to_dict()\npd.DataFrame(df, columns=[\"Total population\"]).T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":false},"cell_type":"code","source":"df = _pyramid_df.copy()\nseries = df[\"Age_bin\"].str.replace(\"+\", \"-122\")\ndf[[\"Age_first\", \"Age_last\"]] = series.str.split(\"-\", expand=True).astype(np.int64)\ndf = df.drop(\"Age_bin\", axis=1)\nseries = df[\"Age_last\"]\ndf = df.apply(lambda x: x[:-2] / (x[-1] - x[-2] + 1), axis=1)\ndf[\"Age\"] = series\ndf = pd.merge(df, pd.DataFrame({\"Age\": np.arange(0, 123, 1)}), on=\"Age\", how=\"right\", sort=True)\ndf = df.fillna(method=\"bfill\").astype(np.int64)\ndf = df.set_index(\"Age\")\npyramid_df = df.copy()\npyramid_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## The number of days go out (template data)\n**As a comment of this notebook, @marcoferrante estimated the number of days persons of each age group usually go out. Thank you for your kind cooperation!!**"},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"# @marcoferrante estimation\n_period_of_life_list = [\n    \"nursery\", \"nursery school\", \"elementary school\", \"middle school\",\n    \"high school\", \"university/work\", \"work\", \"work\", \"work\", \"work\",\n    \"retired\", \"retired\", \"retired\"\n]\ndf = pd.DataFrame(\n    {\n        \"Age_first\": [0, 3, 6, 11, 14, 19, 26, 36, 46, 56, 66, 76, 86],\n        \"Age_last\": [2, 5, 10, 13, 18, 25, 35, 45, 55, 65, 75, 85, 95],\n        \"Period_of_life\": _period_of_life_list,\n        \"Days\": [3, 5, 6, 6, 7, 7, 6, 5, 5, 5, 4, 3, 2]\n    }\n)\n# Adjustment by author\ndf[\"Types\"] = df[\"Period_of_life\"].replace(\n    {\n        \"nursery\": \"school\",\n        \"nursery school\": \"school\",\n        \"elementary school\": \"school\",\n        \"middle school\": \"school\",\n        \"high school\": \"school\",\n        \"university/work\": \"school/work\"\n    }\n)\ndf[\"School\"] = df[[\"Types\", \"Days\"]].apply(lambda x: x[1] if \"school\" in x[0] else 0, axis=1)\ndf[\"Office\"] = df[[\"Types\", \"Days\"]].apply(lambda x: x[1] if \"work\" in x[0] else 0, axis=1)\ndf[\"Others\"] = df[\"Days\"] - df[[\"School\", \"Office\"]].sum(axis=1)\ndf.loc[df[\"Others\"] < 0, \"Others\"] = 0\ndf.loc[df.index[1:5], \"School\"] -= 1\ndf.loc[df.index[1:5], \"Others\"] += 1\ndf.loc[df.index[5], [\"School\", \"Office\", \"Others\"]] = [3, 3, 1]\ndf[[\"School\", \"Office\", \"Others\"]] = df[[\"Days\", \"School\", \"Office\", \"Others\"]].apply(\n    lambda x: x[1:] / sum(x[1:]) * x[0], axis=1\n).astype(np.int64)\ndf.loc[df.index[6:10], \"Others\"] += 1\ndf = df.drop([\"Days\", \"Types\"], axis=1)\n# Show dataset\n_out_df = df.copy()\n_out_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For each country, population pyramid data will be combined to the table. The columns with countriy names are the portion of the total population."},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pyramid_df.cumsum()\ncountries = df.columns[:]\ndf = pd.merge(_out_df, df, left_on=\"Age_last\", right_on=\"Age\", how=\"left\")\n_first = df.loc[df.index[0], countries]\ndf[countries] = df[countries].diff()\ndf.loc[df.index[0], countries] = _first\ndf[countries] = df[countries].apply(lambda x: x / x.sum(), axis=0)\nout_df = df.copy()\nout_df","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"95082af9-f24a-4144-908c-57b025338ab2","_cell_guid":"2598dd2f-8d7b-4dde-8de4-2a2853fd0b4d","trusted":true},"cell_type":"markdown","source":"## Dataset"},{"metadata":{"_uuid":"605ad8fc-3c90-43c4-8a6e-433348e6e021","_cell_guid":"59dee3c4-2ed9-4927-9f88-0bfa6101e686","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"for dirname, _, filenames in os.walk(\"/kaggle/input\"):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c3ebe4cf-2cd1-4d69-9882-8d2cc490e1ea","_cell_guid":"8c2f4e86-2ce9-4aa4-8352-348523a88b51","trusted":true},"cell_type":"markdown","source":"## Functions\nHere, we define the functions to use repeatedly in this notebook."},{"metadata":{"_uuid":"e619de8a-4351-4f6a-97f1-2a07dfc8df8c","_cell_guid":"9aa77813-b9cc-46a4-a77f-88c1b5eb220e","trusted":true},"cell_type":"markdown","source":"### Plotting"},{"metadata":{"_uuid":"102b157f-f1f0-4430-91ba-0660f388c945","_cell_guid":"5b76a2ac-df0d-4c4c-85c6-38c8b147ef93","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def line_plot(df, title, ylabel=\"Cases\", h=None, v=None,\n              xlim=(None, None), ylim=(0, None), math_scale=True, y_logscale=False, y_integer=False):\n    \"\"\"\n    Show chlonological change of the data.\n    \"\"\"\n    ax = df.plot()\n    if math_scale:\n        ax.yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n        ax.ticklabel_format(style=\"sci\",  axis=\"y\",scilimits=(0, 0))\n    if y_logscale:\n        ax.set_yscale(\"log\")\n    if y_integer:\n        fmt = matplotlib.ticker.ScalarFormatter(useOffset=False)\n        fmt.set_scientific(False)\n        ax.yaxis.set_major_formatter(fmt)\n    ax.set_title(title)\n    ax.set_xlabel(None)\n    ax.set_ylabel(ylabel)\n    ax.set_xlim(*xlim)\n    ax.set_ylim(*ylim)\n    ax.legend(bbox_to_anchor=(1.02, 0), loc=\"lower left\", borderaxespad=0)\n    if h is not None:\n        ax.axhline(y=h, color=\"black\", linestyle=\"--\")\n    if v is not None:\n        if not isinstance(v, list):\n            v = [v]\n        for value in v:\n            ax.axvline(x=value, color=\"black\", linestyle=\"--\")\n    plt.tight_layout()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Trend analysis"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def select_area(clean_df, places=None, excluded_places=None, group=\"Date\"):\n    \"\"\"\n    Select the records of the palces.\n    @clean_df <pd.DataFrame>: the clean data\n    @places <list[tuple(<str/None>, <str/None>)]: the list of places\n        - if the list is None, all data will be used\n        - (str, str): both of country and province are specified\n        - (str, None): only country is specified\n        - (None, str) or (None, None): Error\n    @excluded_places <list[tuple(<str/None>, <str/None>)]: the list of excluded places\n        - if the list is None, all data in the \"places\" will be used\n        - (str, str): both of country and province are specified\n        - (str, None): only country is specified\n        - (None, str) or (None, None): Error\n    @group <str or None>: group-by the group, or not perform (None)\n    @return <pd.DataFrame>: index and columns are as same as @ncov_df\n    \"\"\"\n    # Select the target records\n    df = clean_df.copy()\n    c_series = df[\"Country\"]\n    p_series = df[\"Province\"]\n    if places is not None:\n        df = pd.DataFrame(columns=clean_df.columns)\n        for (c, p) in places:\n            if c is None:\n                raise Exception(\"places: Country must be specified!\")\n            if p is None:\n                new_df = clean_df.loc[c_series == c, :]\n            else:\n                new_df = clean_df.loc[(c_series == c) & (p_series == p), :]\n            df = pd.concat([df, new_df], axis=0)\n    if excluded_places is not None:\n        for (c, p) in excluded_places:\n            if c is None:\n                raise Exception(\"excluded_places: Country must be specified!\")\n            if p is None:\n                df = df.loc[c_series != c, :]\n            else:\n                c_df = df.loc[(c_series == c) & (p_series != p), :]\n                other_df = df.loc[c_series != c, :]\n                df = pd.concat([c_df, other_df], axis=0)\n    if group is not None:\n        df = df.groupby(group).sum().reset_index()\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def show_trend(ncov_df, variable=\"Confirmed\", n_changepoints=2, places=None, excluded_places=None):\n    \"\"\"\n    Show trend of log10(@variable) using fbprophet package.\n    @ncov_df <pd.DataFrame>: the clean data\n    @variable <str>: variable name to analyse\n        - if Confirmed, use Infected + Recovered + Deaths\n    @n_changepoints <int>: max number of change points\n    @places <list[tuple(<str/None>, <str/None>)]: the list of places\n        - if the list is None, all data will be used\n        - (str, str): both of country and province are specified\n        - (str, None): only country is specified\n        - (None, str) or (None, None): Error\n    @excluded_places <list[tuple(<str/None>, <str/None>)]: the list of excluded places\n        - if the list is None, all data in the \"places\" will be used\n        - (str, str): both of country and province are specified\n        - (str, None): only country is specified\n        - (None, str) or (None, None): Error\n    \"\"\"\n    # Data arrangement\n    df = select_area(ncov_df, places=places, excluded_places=excluded_places)\n    if variable == \"Confirmed\":\n        df[\"Confirmed\"] = df[[\"Infected\", \"Recovered\", \"Deaths\"]].sum(axis=1)\n    df = df.loc[:, [\"Date\", variable]]\n    df.columns = [\"ds\", \"y\"]\n    # Log10(x)\n    warnings.resetwarnings()\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\")\n        df[\"y\"] = np.log10(df[\"y\"]).replace([np.inf, -np.inf], 0)\n    # fbprophet\n    model = Prophet(growth=\"linear\", daily_seasonality=False, n_changepoints=n_changepoints)\n    model.fit(df)\n    future = model.make_future_dataframe(periods=0)\n    forecast = model.predict(future)\n    # Create figure\n    fig = model.plot(forecast)\n    _ = add_changepoints_to_plot(fig.gca(), model, forecast)\n    plt.title(f\"log10({variable}) over time and chainge points\")\n    plt.ylabel(f\"log10(the number of cases)\")\n    plt.xlabel(\"\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1f5acaa2-fff5-45ba-b371-daafda9ce78c","_cell_guid":"7eb3a21d-006c-43bd-ba1d-82fb46cec274","trusted":true},"cell_type":"markdown","source":"### Dataset arrangement"},{"metadata":{"_uuid":"ae73742e-4671-40d8-bd9f-b172e5894660","_cell_guid":"673e50af-45d8-4a5a-897d-88e88cb03cd8","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def create_target_df(ncov_df, total_population, places=None,\n                     excluded_places=None, start_date=None, date_format=\"%d%b%Y\"):\n    \"\"\"\n    Select the records of the palces, calculate the number of susceptible people,\n     and calculate the elapsed time [day] from the start date of the target dataframe.\n    @ncov_df <pd.DataFrame>: the clean data\n    @total_population <int>: total population in the places\n    @places <list[tuple(<str/None>, <str/None>)]: the list of places\n        - if the list is None, all data will be used\n        - (str, str): both of country and province are specified\n        - (str, None): only country is specified\n        - (None, str) or (None, None): Error\n    @excluded_places <list[tuple(<str/None>, <str/None>)]: the list of excluded places\n        - if the list is None, all data in the \"places\" will be used\n        - (str, str): both of country and province are specified\n        - (str, None): only country is specified\n        - (None, str) or (None, None): Error\n    @start_date <str>: the start date or None\n    @date_format <str>: format of @start_date\n    @return <tuple(2 objects)>:\n        - 1. start_date <pd.Timestamp>: the start date of the selected records\n        - 2. target_df <pd.DataFrame>:\n            - column T: elapsed time [min] from the start date of the dataset\n            - column Susceptible: the number of patients who are in the palces but not infected/recovered/died\n            - column Infected: the number of infected cases\n            - column Recovered: the number of recovered cases\n            - column Deaths: the number of death cases\n    \"\"\"\n    # Select the target records\n    df = select_area(ncov_df, places=places, excluded_places=excluded_places)\n    if start_date is not None:\n        df = df.loc[df[\"Date\"] > datetime.strptime(start_date, date_format), :]\n    start_date = df.loc[df.index[0], \"Date\"]\n    # column T\n    df[\"T\"] = ((df[\"Date\"] - start_date).dt.total_seconds() / 60).astype(int)\n    # coluns except T\n    df[\"Susceptible\"] = total_population - df[\"Infected\"] - df[\"Recovered\"] - df[\"Deaths\"]\n    response_variables = [\"Susceptible\", \"Infected\", \"Recovered\", \"Deaths\"]\n    # Return\n    target_df = df.loc[:, [\"T\", *response_variables]]\n    return (start_date, target_df)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9f164794-196a-4755-9d8f-083370aab0a3","_cell_guid":"5102c179-986a-40a7-91a2-711e3c9215fe","trusted":true},"cell_type":"markdown","source":"### Numerical simulation\nWe will perform numerical analysis to solve the ODE using scipy.integrate.solve_ivp function."},{"metadata":{"_uuid":"6007f8a5-764f-4e7e-95b3-ba8796f66402","_cell_guid":"95bcd2ad-14bb-42d1-8db0-d6dfda502f69","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def simulation(model, initials, step_n, **params):\n    \"\"\"\n    Solve ODE of the model.\n    @model <ModelBase>: the model\n    @initials <tuple[float]>: the initial values\n    @step_n <int>: the number of steps\n    \"\"\"\n    tstart, dt, tend = 0, 1, step_n\n    sol = solve_ivp(\n        fun=model(**params),\n        # Implicit Runge-Kutta method of the Radau IIA family of order 5\n        # method=\"Radau\",\n        t_span=[tstart, tend],\n        y0=np.array(initials, dtype=np.float64),\n        t_eval=np.arange(tstart, tend + dt, dt),\n        dense_output=True\n    )\n    t_df = pd.Series(data=sol[\"t\"], name=\"t\")\n    y_df = pd.DataFrame(data=sol[\"y\"].T.copy(), columns=model.VARIABLES)\n    sim_df = pd.concat([t_df, y_df], axis=1)\n    return sim_df","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"53c1b7dd-c0b2-4d45-b6d2-d36bca1bd032","_cell_guid":"c6d1b626-d8ec-4984-86e2-cb62df954ce6","trusted":true},"cell_type":"markdown","source":"### Parameter Estimation using Optuna"},{"metadata":{"_uuid":"22614672-80dc-41b5-b570-7b85ae2c3cee","_cell_guid":"6a5b8c75-becf-4419-8370-9e700a356853","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"class Estimator(object):\n    def __init__(self, model, ncov_df, total_population, name=None, places=None,\n                 excluded_places=None, start_date=None, date_format=\"%d%b%Y\", **kwargs):\n        \"\"\"\n        Set training data.\n        @model <ModelBase>: the model\n        @name <str>: name of the area\n        @kwargs: fixed parameter of the model\n        @the other params: See the function named create_target_df()\n        \"\"\"\n        self.fixed_param_dict = kwargs.copy()\n        dataset = model.create_dataset(\n            ncov_df, total_population, places=places, excluded_places=excluded_places,\n            start_date=start_date, date_format=date_format\n        )\n        self.start_time, self.initials, self.Tend, self.train_df = dataset\n        self.total_population = total_population\n        self.name = name\n        self.model = model\n        self.param_dict = dict()\n        self.study = None\n        self.optimize_df = None\n\n    def run(self, n_trials=500):\n        \"\"\"\n        Try estimation (optimization of parameters and tau).\n        @n_trials <int>: the number of trials\n        \"\"\"\n        if self.study is None:\n            self.study = optuna.create_study(direction=\"minimize\")\n        self.study.optimize(\n            lambda x: self.objective(x),\n            n_trials=n_trials,\n            n_jobs=-1\n        )\n        param_dict = self.study.best_params.copy()\n        param_dict.update(self.fixed_param_dict)\n        param_dict[\"R0\"] = self.calc_r0()\n        param_dict[\"score\"] = self.score()\n        param_dict.update(self.calc_days_dict())\n        self.param_dict = param_dict.copy()\n        return param_dict\n\n    def history_df(self):\n        \"\"\"\n        Return the hsitory of optimization.\n        @return <pd.DataFrame>\n        \"\"\"\n        optimize_df = self.study.trials_dataframe()\n        optimize_df[\"time[s]\"] = optimize_df[\"datetime_complete\"] - optimize_df[\"datetime_start\"]\n        optimize_df[\"time[s]\"] = optimize_df[\"time[s]\"].dt.total_seconds()\n        self.optimize_df = optimize_df.drop([\"datetime_complete\", \"datetime_start\"], axis=1)\n        return self.optimize_df.sort_values(\"value\", ascending=True)\n\n    def history_graph(self):\n        \"\"\"\n        Show the history of parameter search using pair-plot.\n        \"\"\"\n        if self.optimize_df is None:\n            self.history_df()\n        df = self.optimize_df.copy()\n        sns.pairplot(df.loc[:, df.columns.str.startswith(\"params_\")], diag_kind=\"kde\", markers=\"+\")\n        plt.show()\n\n    def objective(self, trial):\n        # Time\n        if \"tau\" in self.fixed_param_dict.keys():\n            tau = self.fixed_param_dict[\"tau\"]\n        else:\n            tau = trial.suggest_int(\"tau\", 1, 1440)\n        # Apply adjusted Exponential Moving Average on the training data\n        #.set_index(\"T\").ewm(span=7, adjust=True).mean().reset_index()\n        train_df_divided = self.train_df.copy()\n        train_df_divided[\"t\"] = (train_df_divided[\"T\"] / tau).astype(np.int64) # int to np.int64\n        # Parameters\n        p_dict = dict()\n        for (name, info) in self.model.param_dict(train_df_divided).items():\n            if name in self.fixed_param_dict.keys():\n                param = self.fixed_param_dict[name]\n            elif info[0] == \"float\":\n                param = trial.suggest_uniform(name, info[1], info[2])\n            else:\n                param = trial.suggest_int(name, info[1], info[2])\n            p_dict[name] = param\n        # Simulation\n        t_end = train_df_divided.loc[train_df_divided.index[-1], \"t\"]\n        sim_df = simulation(self.model, self.initials, step_n=t_end, **p_dict)\n        return self.error_f(train_df_divided, sim_df)\n\n    def error_f(self, train_df_divided, sim_df):\n        \"\"\"\n        We need to minimize the difference of the observed values and estimated values.\n        This function calculate the difference of the estimated value and obsereved value.\n        \"\"\"\n        df = pd.merge(train_df_divided, sim_df, on=\"t\", suffixes=(\"_observed\", \"_estimated\"))\n        diffs = [\n            # Weighted Average: the recent data is more important\n            p * np.average(\n                abs(df[f\"{v}_observed\"] - df[f\"{v}_estimated\"]) / (df[f\"{v}_observed\"] * self.total_population + 1),\n                weights=df[\"t\"]\n            )\n            for (p, v) in zip(self.model.PRIORITIES, self.model.VARIABLES)\n        ]\n        return sum(diffs) * (self.total_population ** 2)\n\n    def compare_df(self):\n        \"\"\"\n        Show the taining data and simulated data in one dataframe.\n        \n        \"\"\"\n        est_dict = self.study.best_params.copy()\n        est_dict.update(self.fixed_param_dict)\n        tau = est_dict[\"tau\"]\n        est_dict.pop(\"tau\")\n        observed_df = self.train_df.drop(\"T\", axis=1)\n        observed_df[\"t\"] = (self.train_df[\"T\"] / tau).astype(int)\n        t_end = observed_df.loc[observed_df.index[-1], \"t\"]\n        sim_df = simulation(self.model, self.initials, step_n=t_end, **est_dict)\n        df = pd.merge(observed_df, sim_df, on=\"t\", suffixes=(\"_observed\", \"_estimated\"))\n        df = df.set_index(\"t\")\n        return df\n\n    def compare_graph(self):\n        \"\"\"\n        Compare obsereved and estimated values in graphs.\n        \"\"\"\n        df = self.compare_df()\n        use_variables = [\n            v for (i, (p, v)) in enumerate(zip(self.model.PRIORITIES, self.model.VARIABLES))\n            if p != 0 and i != 0\n        ]\n        val_len = len(use_variables) + 1\n        fig, axes = plt.subplots(ncols=1, nrows=val_len, figsize=(9, 6 * val_len / 2))\n        for (ax, v) in zip(axes.ravel()[1:],use_variables):\n            df[[f\"{v}_observed\", f\"{v}_estimated\"]].plot.line(\n                ax=ax, ylim=(0, None), sharex=True,\n                title=f\"{self.model.NAME}: Comparison of observed/estimated {v}(t)\"\n            )\n            ax.yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n            ax.ticklabel_format(style=\"sci\",  axis=\"y\",scilimits=(0, 0))\n            ax.legend(bbox_to_anchor=(1.02, 0), loc=\"lower left\", borderaxespad=0)\n        for v in use_variables:\n            df[f\"{v}_diff\"] = df[f\"{v}_observed\"] - df[f\"{v}_estimated\"]\n            df[f\"{v}_diff\"].plot.line(\n                ax=axes.ravel()[0], sharex=True,\n                title=f\"{self.model.NAME}: observed - estimated\"\n            )\n        axes.ravel()[0].axhline(y=0, color=\"black\", linestyle=\"--\")\n        axes.ravel()[0].yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n        axes.ravel()[0].ticklabel_format(style=\"sci\",  axis=\"y\",scilimits=(0, 0))\n        axes.ravel()[0].legend(bbox_to_anchor=(1.02, 0), loc=\"lower left\", borderaxespad=0)\n        fig.tight_layout()\n        fig.show()\n    \n    def calc_r0(self):\n        \"\"\"\n        Calculate R0.\n        \"\"\"\n        est_dict = self.study.best_params.copy()\n        est_dict.update(self.fixed_param_dict)\n        est_dict.pop(\"tau\")\n        model_instance = self.model(**est_dict)\n        return model_instance.calc_r0()\n\n    def calc_days_dict(self):\n        \"\"\"\n        Calculate 1/beta etc.\n        \"\"\"\n        est_dict = self.study.best_params.copy()\n        est_dict.update(self.fixed_param_dict)\n        tau = est_dict[\"tau\"]\n        est_dict.pop(\"tau\")\n        model_instance = self.model(**est_dict)\n        return model_instance.calc_days_dict(tau)\n\n    def predict_df(self, step_n):\n        \"\"\"\n        Predict the values in the future.\n        @step_n <int>: the number of steps\n        @return <pd.DataFrame>: predicted data for measurable variables.\n        \"\"\"\n        est_dict = self.study.best_params.copy()\n        est_dict.update(self.fixed_param_dict)\n        tau = est_dict[\"tau\"]\n        est_dict.pop(\"tau\")\n        df = simulation(self.model, self.initials, step_n=step_n, **est_dict)\n        df[\"Time\"] = (df[\"t\"] * tau).apply(lambda x: timedelta(minutes=x)) + self.start_time\n        df = df.set_index(\"Time\").drop(\"t\", axis=1)\n        df = (df * self.total_population).astype(np.int64)\n        upper_cols = [n.upper() for n in df.columns]\n        df.columns = upper_cols\n        df = self.model.calc_variables_reverse(df).drop(upper_cols, axis=1)\n        return df\n\n    def predict_graph(self, step_n, name=None, excluded_cols=None):\n        \"\"\"\n        Predict the values in the future and create a figure.\n        @step_n <int>: the number of steps\n        @name <str>: name of the area\n        @excluded_cols <list[str]>: the excluded columns in the figure\n        \"\"\"\n        if self.name is not None:\n            name = self.name\n        else:\n            name = str() if name is None else name\n        df = self.predict_df(step_n=step_n)\n        if excluded_cols is not None:\n            df = df.drop(excluded_cols, axis=1)\n        r0 = self.param_dict[\"R0\"]\n        title = f\"Prediction in {name} with {self.model.NAME} model: R0 = {r0}\"\n        line_plot(df, title, v= datetime.today(), h=self.total_population)\n\n    def score(self):\n        \"\"\"\n        Return the sum of differences of observed and estimated values devided by the number of steps.\n        \"\"\"\n        variables = self.model.VARIABLES[:]\n        compare_df = self.compare_df()\n        score = 0\n        for v in variables:\n            score += abs(compare_df[f\"{v}_observed\"] - compare_df[f\"{v}_estimated\"]).sum()\n        score = score / len(compare_df)\n        return score\n\n    def info(self):\n        \"\"\"\n        Return Estimater information.\n        @return <tupple[object]>:\n            - <ModelBase>: model\n            - <dict[str]=str>: name, total_population, start_time, tau\n            - <dict[str]=float>: values of parameters of model\n        \"\"\"\n        param_dict = self.study.best_params.copy()\n        param_dict.update(self.fixed_param_dict)\n        info_dict = {\n            \"name\": self.name,\n            \"total_population\": self.total_population,\n            \"start_time\": self.start_time,\n            \"tau\": param_dict[\"tau\"],\n            \"initials\": self.initials\n        }\n        param_dict.pop(\"tau\")\n        return (self.model, info_dict, param_dict)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3922e417-890c-431a-a8bf-507662ce70e8","_cell_guid":"decfa29f-ccbe-4cad-9574-5ff0e771aae7","trusted":true},"cell_type":"markdown","source":"### Description of math model"},{"metadata":{"_uuid":"02915ddd-c0fd-4544-9e47-0a7b4f249cc2","_cell_guid":"eed8b0f8-1e0e-4c8c-8f87-02467bae6912","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"class ModelBase(object):\n    NAME = \"Model\"\n    VARIABLES = [\"x\"]\n    PRIORITIES = np.array([1])\n    QUANTILE_RANGE = [0.3, 0.7]\n\n    @classmethod\n    def param_dict(cls, train_df_divided=None, q_range=None):\n        \"\"\"\n        Define parameters without tau. This function should be overwritten.\n        @train_df_divided <pd.DataFrame>:\n            - column: t and non-dimensional variables\n        @q_range <list[float, float]>: quantile rage of the parameters calculated by the data\n        @return <dict[name]=(type, min, max):\n            @type <str>: \"float\" or \"int\"\n            @min <float/int>: min value\n            @max <float/int>: max value\n        \"\"\"\n        param_dict = dict()\n        return param_dict\n\n    @staticmethod\n    def calc_variables(df):\n        \"\"\"\n        Calculate the variables of the model.\n        This function should be overwritten.\n        @df <pd.DataFrame>\n        @return <pd.DataFrame>\n        \"\"\"\n        return df\n\n    @staticmethod\n    def calc_variables_reverse(df):\n        \"\"\"\n        Calculate measurable variables using the variables of the model.\n        This function should be overwritten.\n        @df <pd.DataFrame>\n        @return <pd.DataFrame>\n        \"\"\"\n        return df\n\n    @classmethod\n    def create_dataset(cls, ncov_df, total_population, places=None,\n                       excluded_places=None, start_date=None, date_format=\"%d%b%Y\"):\n        \"\"\"\n        Create dataset with the model-specific varibles.\n        The variables will be divided by total population.\n        The column names (not include T) will be lower letters.\n        @params: See the function named create_target_df()\n        @return <tuple(objects)>:\n            - start_date <pd.Timestamp>\n            - initials <tuple(float)>: the initial values\n            - Tend <int>: the last value of T\n            - df <pd.DataFrame>: the dataset\n        \"\"\"\n        start_date, target_df = create_target_df(\n            ncov_df, total_population, places=places, excluded_places=excluded_places,\n            start_date=start_date, date_format=date_format\n        )\n        df = cls.calc_variables(target_df).set_index(\"T\") / total_population\n        df.columns = [n.lower() for n in df.columns]\n        initials = df.iloc[0, :].values\n        df = df.reset_index()\n        Tend = df.iloc[-1, 0]\n        return (start_date, initials, Tend, df)\n\n    def calc_r0(self):\n        \"\"\"\n        Calculate R0. This function should be overwritten.\n        \"\"\"\n        return None\n\n    def calc_days_dict(self, tau):\n        \"\"\"\n        Calculate 1/beta [day] etc.\n        This function should be overwritten.\n        @param tau <int>: tau value [hour]\n        \"\"\"\n        return dict()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1bc607ad-3e75-445b-9c90-d88d84783237","_cell_guid":"52b04482-dbfb-4f59-a148-0d696eccfc3a","trusted":true},"cell_type":"markdown","source":"#### SIR model"},{"metadata":{"_uuid":"f4437e32-5ceb-4bd3-9efe-95b84dbcefc8","_cell_guid":"eada8314-baf7-49b0-8d26-d788c45f4cfb","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"class SIR(ModelBase):\n    NAME = \"SIR\"\n    VARIABLES = [\"x\", \"y\", \"z\"]\n    PRIORITIES = np.array([1, 1, 1])\n\n    def __init__(self, rho, sigma):\n        super().__init__()\n        self.rho = float(rho)\n        self.sigma = float(sigma)\n\n    def __call__(self, t, X):\n        # x, y, z = [X[i] for i in range(len(self.VARIABLES))]\n        # dxdt = - self.rho * x * y\n        # dydt = self.rho * x * y - self.sigma * y\n        # dzdt = self.sigma * y\n        dxdt = - self.rho * X[0] * X[1]\n        dydt = self.rho * X[0] * X[1] - self.sigma * X[1]\n        dzdt = self.sigma * X[1]\n        return np.array([dxdt, dydt, dzdt])\n\n    @classmethod\n    def param_dict(cls, train_df_divided=None, q_range=None):\n        param_dict = super().param_dict()\n        q_range = super().QUANTILE_RANGE[:] if q_range is None else q_range\n        if train_df_divided is None:\n            param_dict[\"rho\"] = (\"float\", 0, 1)\n            param_dict[\"sigma\"] = (\"float\", 0, 1)\n        else:\n            df = train_df_divided.copy()\n            # rho = - (dx/dt) / x / y\n            rho_series = 0 - df[\"x\"].diff() / df[\"t\"].diff() / df[\"x\"] / df[\"y\"]\n            param_dict[\"rho\"] = (\"float\", *rho_series.quantile(q_range))\n            # sigma = (dz/dt) / y\n            sigma_series = df[\"z\"].diff() / df[\"t\"].diff() / df[\"y\"]\n            param_dict[\"sigma\"] = (\"float\", *sigma_series.quantile(q_range))\n        return param_dict\n\n    @staticmethod\n    def calc_variables(df):\n        df[\"X\"] = df[\"Susceptible\"]\n        df[\"Y\"] = df[\"Infected\"]\n        df[\"Z\"] = df[\"Recovered\"] + df[\"Deaths\"]\n        return df.loc[:, [\"T\", \"X\", \"Y\", \"Z\"]]\n\n    @staticmethod\n    def calc_variables_reverse(df):\n        df[\"Susceptible\"] = df[\"X\"]\n        df[\"Infected\"] = df[\"Y\"]\n        df[\"Recovered/Deaths\"] = df[\"Z\"]\n        return df\n\n    def calc_r0(self):\n        if self.sigma == 0:\n            return np.nan\n        r0 = self.rho / self.sigma\n        return round(r0, 2)\n\n    def calc_days_dict(self, tau):\n        _dict = dict()\n        _dict[\"1/beta [day]\"] = int(tau / 24 / 60 / self.rho)\n        _dict[\"1/gamma [day]\"] = int(tau / 24 / 60 / self.sigma)\n        return _dict","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"da7442b6-fa0b-4bf2-bb2d-70625b5b944f","_cell_guid":"945c3774-cf7c-40c8-b63f-d852df420781","trusted":true},"cell_type":"markdown","source":"#### SIR-D model"},{"metadata":{"_uuid":"66a9f00d-1639-4fef-b66e-9fe8adb3f7dc","_cell_guid":"4bbd4ca2-bf18-440a-8fef-a81f8694957f","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"class SIRD(ModelBase):\n    NAME = \"SIR-D\"\n    VARIABLES = [\"x\", \"y\", \"z\", \"w\"]\n    PRIORITIES = np.array([1, 10, 10, 2])\n\n    def __init__(self, kappa, rho, sigma):\n        super().__init__()\n        self.kappa = float(kappa)\n        self.rho = float(rho)\n        self.sigma = float(sigma)\n\n    def __call__(self, t, X):\n        # x, y, z, w = [X[i] for i in range(len(self.VARIABLES))]\n        # dxdt = - self.rho * x * y\n        # dydt = self.rho * x * y - (self.sigma + self.kappa) * y\n        # dzdt = self.sigma * y\n        # dwdt = self.kappa * y\n        dxdt = - self.rho * X[0] * X[1]\n        dydt = self.rho * X[0] * X[1] - (self.sigma + self.kappa) * X[1]\n        dzdt = self.sigma * X[1]\n        dwdt = self.kappa * X[1]\n        return np.array([dxdt, dydt, dzdt, dwdt])\n\n    @classmethod\n    def param_dict(cls, train_df_divided=None, q_range=None):\n        param_dict = super().param_dict()\n        q_range = super().QUANTILE_RANGE[:] if q_range is None else q_range\n        if train_df_divided is None:\n            param_dict[\"kappa\"] = (\"float\", 0, 1)\n            param_dict[\"rho\"] = (\"float\", 0, 1)\n            param_dict[\"sigma\"] = (\"float\", 0, 1)\n        else:\n            df = train_df_divided.copy()\n            # kappa = (dw/dt) / y\n            kappa_series = df[\"w\"].diff() / df[\"t\"].diff() / df[\"y\"]\n            param_dict[\"kappa\"] = (\"float\", *kappa_series.quantile(q_range))\n            # rho = - (dx/dt) / x / y\n            rho_series = 0 - df[\"x\"].diff() / df[\"t\"].diff() / df[\"x\"] / df[\"y\"]\n            param_dict[\"rho\"] = (\"float\", *rho_series.quantile(q_range))\n            # sigma = (dz/dt) / y\n            sigma_series = df[\"z\"].diff() / df[\"t\"].diff() / df[\"y\"]\n            param_dict[\"sigma\"] = (\"float\", *sigma_series.quantile(q_range))\n        return param_dict\n\n    @staticmethod\n    def calc_variables(df):\n        df[\"X\"] = df[\"Susceptible\"]\n        df[\"Y\"] = df[\"Infected\"]\n        df[\"Z\"] = df[\"Recovered\"]\n        df[\"W\"] = df[\"Deaths\"]\n        return df.loc[:, [\"T\", \"X\", \"Y\", \"Z\", \"W\"]]\n\n    @staticmethod\n    def calc_variables_reverse(df):\n        df[\"Susceptible\"] = df[\"X\"]\n        df[\"Infected\"] = df[\"Y\"]\n        df[\"Recovered\"] = df[\"Z\"]\n        df[\"Deaths\"] = df[\"W\"]\n        return df\n\n    def calc_r0(self):\n        try:\n            r0 = self.rho / (self.sigma + self.kappa)\n        except ZeroDivisionError:\n            return np.nan\n        return round(r0, 2)\n\n\n    def calc_days_dict(self, tau):\n        _dict = dict()\n        if self.kappa == 0:\n            _dict[\"1/alpha2 [day]\"] = 0\n        else:\n            _dict[\"1/alpha2 [day]\"] = int(tau / 24 / 60 / self.kappa)\n        _dict[\"1/beta [day]\"] = int(tau / 24 / 60 / self.rho)\n        if self.sigma == 0:\n            _dict[\"1/gamma [day]\"] = 0\n        else:\n            _dict[\"1/gamma [day]\"] = int(tau / 24 / 60 / self.sigma)\n        return _dict","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c178ee57-8983-4f55-84dd-71997fec53ce","_cell_guid":"1e115ae8-7e81-4055-896d-95889d3c973e","trusted":true},"cell_type":"markdown","source":"#### SIR-F model"},{"metadata":{"_uuid":"04c1a590-1767-4ab1-b7de-d58d8ca69841","_cell_guid":"b4fc216a-fe30-4316-90e1-2034c5abff38","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"class SIRF(ModelBase):\n    NAME = \"SIR-F\"\n    VARIABLES = [\"x\", \"y\", \"z\", \"w\"]\n    PRIORITIES = np.array([1, 10, 10, 2])\n\n    def __init__(self, theta, kappa, rho, sigma):\n        super().__init__()\n        self.theta = float(theta)\n        self.kappa = float(kappa)\n        self.rho = float(rho)\n        self.sigma = float(sigma)\n\n    def __call__(self, t, X):\n        # x, y, z, w = [X[i] for i in range(len(self.VARIABLES))]\n        # dxdt = - self.rho * x * y\n        # dydt = self.rho * (1 - self.theta) * x * y - (self.sigma + self.kappa) * y\n        # dzdt = self.sigma * y\n        # dwdt = self.rho * self.theta * x * y + self.kappa * y\n        dxdt = - self.rho * X[0] * X[1]\n        dydt = self.rho * (1 - self.theta) * X[0] * X[1] - (self.sigma + self.kappa) * X[1]\n        dzdt = self.sigma * X[1]\n        dwdt = self.rho * self.theta * X[0] * X[1] + self.kappa * X[1]\n        return np.array([dxdt, dydt, dzdt, dwdt])\n\n    @classmethod\n    def param_dict(cls, train_df_divided=None, q_range=None):\n        param_dict = super().param_dict()\n        q_range = super().QUANTILE_RANGE[:] if q_range is None else q_range\n        param_dict[\"theta\"] = (\"float\", 0, 1)\n        param_dict[\"kappa\"] = (\"float\", 0, 1)\n        if train_df_divided is None:\n            param_dict[\"rho\"] = (\"float\", 0, 1)\n            param_dict[\"sigma\"] = (\"float\", 0, 1)\n        else:\n            df = train_df_divided.copy()\n            # rho = - (dx/dt) / x / y\n            rho_series = 0 - df[\"x\"].diff() / df[\"t\"].diff() / df[\"x\"] / df[\"y\"]\n            param_dict[\"rho\"] = (\"float\", *rho_series.quantile(q_range))\n            # sigma = (dz/dt) / y\n            sigma_series = df[\"z\"].diff() / df[\"t\"].diff() / df[\"y\"]\n            param_dict[\"sigma\"] = (\"float\", *sigma_series.quantile(q_range))\n        return param_dict\n\n    @staticmethod\n    def calc_variables(df):\n        df[\"X\"] = df[\"Susceptible\"]\n        df[\"Y\"] = df[\"Infected\"]\n        df[\"Z\"] = df[\"Recovered\"]\n        df[\"W\"] = df[\"Deaths\"]\n        return df.loc[:, [\"T\", \"X\", \"Y\", \"Z\", \"W\"]]\n\n    @staticmethod\n    def calc_variables_reverse(df):\n        df[\"Susceptible\"] = df[\"X\"]\n        df[\"Infected\"] = df[\"Y\"]\n        df[\"Recovered\"] = df[\"Z\"]\n        df[\"Fatal\"] = df[\"W\"]\n        return df\n\n    def calc_r0(self):\n        try:\n            r0 = self.rho * (1 - self.theta) / (self.sigma + self.kappa)\n        except ZeroDivisionError:\n            return np.nan\n        return round(r0, 2)\n\n    def calc_days_dict(self, tau):\n        _dict = dict()\n        _dict[\"alpha1 [-]\"] = round(self.theta, 3)\n        if self.kappa == 0:\n            _dict[\"1/alpha2 [day]\"] = 0\n        else:\n            _dict[\"1/alpha2 [day]\"] = int(tau / 24 / 60 / self.kappa)\n        _dict[\"1/beta [day]\"] = int(tau / 24 / 60 / self.rho)\n        if self.sigma == 0:\n            _dict[\"1/gamma [day]\"] = 0\n        else:\n            _dict[\"1/gamma [day]\"] = int(tau / 24 / 60 / self.sigma)\n        return _dict","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### SEWIR-F model"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"class SEWIRF(ModelBase):\n    NAME = \"SEWIR-F\"\n    VARIABLES = [\"x1\", \"x2\", \"x3\", \"y\", \"z\", \"w\"]\n    PRIORITIES = np.array([0, 0, 0, 10, 10, 2])\n\n    def __init__(self, theta, kappa, rho1, rho2, rho3, sigma):\n        super().__init__()\n        self.theta = float(theta)\n        self.kappa = float(kappa)\n        self.rho1 = float(rho1)\n        self.rho2 = float(rho2)\n        self.rho3 = float(rho3)\n        self.sigma = float(sigma)\n\n    def __call__(self, t, X):\n        # x1, x2, y, z, w = [X[i] for i in range(len(self.VARIABLES))]\n        # dx1dt = - self.rho1 * x1 * (x3 + y)\n        # dx2dt = self.rho1 * x1 * (x3 + y) - self.rho2 * x2\n        # dx3dt = self.rho2 * x2 - self.rho3 * x3\n        # dydt = self.rho3 * (1 - self.theta) * x3 - (self.sigma + self.kappa) * y\n        # dzdt = self.sigma * y\n        # dwdt = self.rho3 * self.theta * x3 + self.kappa * y\n        dx1dt = - self.rho1 * X[0] * (X[2] + X[3])\n        dx2dt = self.rho1 * X[0] * (X[2] + X[3]) - self.rho2 * X[1]\n        dx3dt = self.rho2 * X[1] - self.rho3 * X[2]\n        dydt = self.rho3 * (1 - self.theta) * X[2] - (self.sigma + self.kappa) * X[3]\n        dzdt = self.sigma * X[3]\n        dwdt = self.rho3 * self.theta * X[2] + self.kappa * X[3]\n        return np.array([dx1dt, dx2dt, dx3dt, dydt, dzdt, dwdt])\n\n    @classmethod\n    def param_dict(cls, train_df_divided=None, q_range=None):\n        param_dict = super().param_dict()\n        q_range = super().QUANTILE_RANGE[:] if q_range is None else q_range\n        param_dict[\"theta\"] = (\"float\", 0, 1)\n        param_dict[\"kappa\"] = (\"float\", 0, 1)\n        param_dict[\"rho1\"] = (\"float\", 0, 1)\n        param_dict[\"rho2\"] = (\"float\", 0, 1)\n        param_dict[\"rho3\"] = (\"float\", 0, 1)\n        if train_df_divided is None:\n            param_dict[\"sigma\"] = (\"float\", 0, 1)\n        else:\n            df = train_df_divided.copy()\n            # sigma = (dz/dt) / y\n            sigma_series = df[\"z\"].diff() / df[\"t\"].diff() / df[\"y\"]\n            param_dict[\"sigma\"] = (\"float\", *sigma_series.quantile(q_range))\n        return param_dict\n\n    @staticmethod\n    def calc_variables(df):\n        df[\"X1\"] = df[\"Susceptible\"]\n        df[\"X2\"] = 0\n        df[\"X3\"] = 0\n        df[\"Y\"] = df[\"Infected\"]\n        df[\"Z\"] = df[\"Recovered\"]\n        df[\"W\"] = df[\"Deaths\"]\n        return df.loc[:, [\"T\", \"X1\", \"X2\", \"X3\", \"Y\", \"Z\", \"W\"]]\n\n    @staticmethod\n    def calc_variables_reverse(df):\n        df[\"Susceptible\"] = df[\"X1\"]\n        df[\"Infected\"] = df[\"Y\"]\n        df[\"Recovered\"] = df[\"Z\"]\n        df[\"Fatal\"] = df[\"W\"]\n        df[\"Exposed\"] = df[\"X2\"]\n        df[\"Waiting\"] = df[\"X3\"]\n        return df\n\n    def calc_r0(self):\n        try:\n            r0 = self.rho1 * (1 - self.theta) / (self.sigma + self.kappa)\n        except ZeroDivisionError:\n            return np.nan\n        return round(r0, 2)\n\n    def calc_days_dict(self, tau):\n        _dict = dict()\n        _dict[\"alpha1 [-]\"] = round(self.theta, 3)\n        if self.kappa == 0:\n            _dict[\"1/alpha2 [day]\"] = 0\n        else:\n            _dict[\"1/alpha2 [day]\"] = int(tau / 24 / 60 / self.kappa)\n        _dict[\"1/beta1 [day]\"] = int(tau / 24 / 60 / self.rho1)\n        _dict[\"1/beta2 [day]\"] = int(tau / 24 / 60 / self.rho2)\n        _dict[\"1/beta3 [day]\"] = int(tau / 24 / 60 / self.rho3)\n        if self.sigma == 0:\n            _dict[\"1/gamma [day]\"] = 0\n        else:\n            _dict[\"1/gamma [day]\"] = int(tau / 24 / 60 / self.sigma)\n        return _dict","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c713d3b8-105c-4cb0-82ed-dc1f54011715","_cell_guid":"acd82be6-702c-46fb-8b36-bf8b9afe9be4","trusted":true},"cell_type":"markdown","source":"#### SIR-FV model"},{"metadata":{"_uuid":"2a3978f2-82e3-4945-a981-4a6372e1bb20","_cell_guid":"25dec87e-96eb-4198-832e-6babe9381e4c","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"class SIRFV(ModelBase):\n    NAME = \"SIR-FV\"\n    VARIABLES = [\"x\", \"y\", \"z\", \"w\"]\n    PRIORITIES = np.array([1, 10, 10, 2])\n\n    def __init__(self, theta, kappa, rho, sigma, omega=None, n=None, v_per_day=None):\n        \"\"\"\n        (n and v_per_day) or omega must be applied.\n        @n <float or int>: total population\n        @v_par_day <float or int>: vacctinated persons per day\n        \"\"\"\n        super().__init__()\n        self.theta = float(theta)\n        self.kappa = float(kappa)\n        self.rho = float(rho)\n        self.sigma = float(sigma)\n        if omega is None:\n            try:\n                self.omega = float(v_per_day) / float(n)\n            except TypeError:\n                s = \"Neither (n and va_per_day) nor omega must be applied!\"\n                raise TypeError(s)\n        else:\n            self.omega = float(omega)\n\n    def __call__(self, t, X):\n        # x, y, z, w = [X[i] for i in range(len(self.VARIABLES))]\n        # x with vacctination\n        dxdt = - self.rho * X[0] * X[1] - self.omega\n        dxdt = 0 - X[0] if X[0] + dxdt < 0 else dxdt\n        # y, z, w\n        dydt = self.rho * (1 - self.theta) * X[0] * X[1] - (self.sigma + self.kappa) * X[1]\n        dzdt = self.sigma * X[1]\n        dwdt = self.rho * self.theta * X[0] * X[1] + self.kappa * X[1]\n        return np.array([dxdt, dydt, dzdt, dwdt])\n\n    @classmethod\n    def param_dict(cls, train_df_divided=None, q_range=None):\n        param_dict = super().param_dict()\n        q_range = super().QUANTILE_RANGE[:] if q_range is None else q_range\n        param_dict[\"theta\"] = (\"float\", 0, 1)\n        param_dict[\"kappa\"] = (\"float\", 0, 1)\n        param_dict[\"omega\"] = (\"float\", 0, 1)\n        if train_df_divided is None:\n            param_dict[\"rho\"] = (\"float\", 0, 1)\n            param_dict[\"sigma\"] = (\"float\", 0, 1)\n        else:\n            df = train_df_divided.copy()\n            # rho = - (dx/dt) / x / y\n            rho_series = 0 - df[\"x\"].diff() / df[\"t\"].diff() / df[\"x\"] / df[\"y\"]\n            param_dict[\"rho\"] = (\"float\", *rho_series.quantile(q_range))\n            # sigma = (dz/dt) / y\n            sigma_series = df[\"z\"].diff() / df[\"t\"].diff() / df[\"y\"]\n            param_dict[\"sigma\"] = (\"float\", *sigma_series.quantile(q_range))\n        return param_dict\n\n    @staticmethod\n    def calc_variables(df):\n        df[\"X\"] = df[\"Susceptible\"]\n        df[\"Y\"] = df[\"Infected\"]\n        df[\"Z\"] = df[\"Recovered\"]\n        df[\"W\"] = df[\"Deaths\"]\n        return df.loc[:, [\"T\", \"X\", \"Y\", \"Z\", \"W\"]]\n\n    @staticmethod\n    def calc_variables_reverse(df):\n        df[\"Susceptible\"] = df[\"X\"]\n        df[\"Infected\"] = df[\"Y\"]\n        df[\"Recovered\"] = df[\"Z\"]\n        df[\"Fatal\"] = df[\"W\"]\n        df[\"Immuned\"] = 1 - df[[\"X\", \"Y\", \"Z\", \"W\"]].sum(axis=1)\n        return df\n\n    def calc_r0(self):\n        try:\n            r0 = self.rho * (1 - self.theta) / (self.sigma + self.kappa)\n        except ZeroDivisionError:\n            return np.nan\n        return round(r0, 2)\n\n    def calc_days_dict(self, tau):\n        _dict = dict()\n        _dict[\"alpha1 [-]\"] = round(self.theta, 3)\n        if self.kappa == 0:\n            _dict[\"1/alpha2 [day]\"] = 0\n        else:\n            _dict[\"1/alpha2 [day]\"] = int(tau / 24 / 60 / self.kappa)\n        _dict[\"1/beta [day]\"] = int(tau / 24 / 60 / self.rho)\n        if self.sigma == 0:\n            _dict[\"1/gamma [day]\"] = 0\n        else:\n            _dict[\"1/gamma [day]\"] = int(tau / 24 / 60 / self.sigma)\n        return _dict","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b6456fea-dbb4-429f-bddd-f2f28adb2850","_cell_guid":"b3dc178b-d383-4d93-be08-d7ae4b1641c8","trusted":true},"cell_type":"markdown","source":"### Prediction of the data using some models"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"class Predicter(object):\n    \"\"\"\n    Predict the future using models.\n    \"\"\"\n    def __init__(self, name, total_population, start_time, tau, initials, date_format=\"%d%b%Y\"):\n        \"\"\"\n        @name <str>: place name\n        @total_population <int>: total population\n        @start_time <datatime>: the start time\n        @tau <int>: tau value (time step)\n        @initials <list/tupple/np.array[float]>: initial values of the first model\n        @date_format <str>: date format to display in figures\n        \"\"\"\n        self.name = name\n        self.total_population = total_population\n        self.start_time = start_time\n        self.tau = tau\n        self.date_format = date_format\n        # Un-fixed\n        self.last_time = start_time\n        self.axvlines = list()\n        self.initials = initials\n        self.df = pd.DataFrame()\n        self.title_list = list()\n        self.reverse_f = lambda x: x\n\n    def add(self, model, end_day_n=None, count_from_last=False, vline=True, **param_dict):\n        \"\"\"\n        @model <ModelBase>: the epidemic model\n        @end_day_n <int/None>: day number of the end date (0, 1, 2,...), or None (now)\n            - if @count_from_last <bool> is True, start point will be the last date registered to Predicter\n        @vline <bool>: if True, vertical line will be shown at the end date\n        @**param_dict <dict>: keyword arguments of the model\n        \"\"\"\n        # Validate day nubber, and calculate step number\n        if end_day_n is None:\n            end_time = datetime.now()\n        else:\n            if count_from_last:\n                end_time = self.last_time + timedelta(days=end_day_n)\n            else:\n                end_time = self.start_time + timedelta(days=end_day_n)\n        if end_time <= self.last_time:\n            raise Exception(f\"Model on {end_time.strftime(self.date_format)} has been registered!\")\n        step_n = int((end_time - self.last_time).total_seconds() / 60 / self.tau)\n        self.last_time = end_time\n        # Perform simulation\n        new_df = simulation(model, self.initials, step_n=step_n, **param_dict)\n        new_df[\"t\"] = new_df[\"t\"] + len(self.df)\n        self.df = pd.concat([self.df, new_df], axis=0).fillna(0)\n        self.initials = new_df.set_index(\"t\").iloc[-1, :]\n        # For title\n        if vline:\n            self.axvlines.append(end_time)\n            r0 = model(**param_dict).calc_r0()\n            self.title_list.append(\n                f\"{model.NAME}({r0}, -{end_time.strftime(self.date_format)})\"\n            )\n        # Update reverse function (X, Y,.. to Susceptible, Infected,...)\n        self.reverse_f = model.calc_variables_reverse\n        return self\n\n    def restore_df(self):\n        \"\"\"\n        Return the dimentional simulated data.\n        @return <pd.DataFrame>\n        \"\"\"\n        df = self.df.copy()\n        df[\"Time\"] = self.start_time + df[\"t\"].apply(lambda x: timedelta(minutes=x * self.tau))\n        df = df.drop(\"t\", axis=1).set_index(\"Time\") * self.total_population\n        df = df.astype(np.int64)\n        upper_cols = [n.upper() for n in df.columns]\n        df.columns = upper_cols\n        df = self.reverse_f(df).drop(upper_cols, axis=1)\n        return df\n\n    def restore_graph(self, drop_cols=None, **kwargs):\n        \"\"\"\n        Show the dimentional simulate data as a figure.\n        @drop_cols <list[str]>: the columns not to be shown\n        @kwargs: keyword arguments of line_plot() function\n        \"\"\"\n        df = self.restore_df()\n        if drop_cols is not None:\n            df = df.drop(drop_cols, axis=1)\n        axvlines = [datetime.now(), *self.axvlines] if len(self.axvlines) == 1 else self.axvlines[:]\n        line_plot(\n            df,\n            title=f\"{self.name}: {', '.join(self.title_list)}\",\n            v=axvlines[:-1],\n            h=self.total_population,\n            **kwargs\n        )","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"980b4b4e-b055-4c2a-b06f-823e90a42421","_cell_guid":"6347198d-b95f-495b-9d50-f55e917c77e9","trusted":true},"cell_type":"markdown","source":"## Raw data"},{"metadata":{"_uuid":"bc109822-1f6c-48ac-baaa-13698ef4155e","_cell_guid":"b0ede625-76d1-4c24-b85d-6b949c4c98f1","trusted":true,"_kg_hide-output":false},"cell_type":"code","source":"raw = pd.read_csv(\"/kaggle/input/novel-corona-virus-2019-dataset/covid_19_data.csv\")\nraw.tail()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"73225ddf-46f9-4d8b-bee9-4a5652ecc9fd","_cell_guid":"cde46880-86b1-4177-9c1a-dc3b34e51935","trusted":true,"_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"raw.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"958fa8de-84d8-4b89-aa22-4a14838ee235","_cell_guid":"fb0a8feb-e0f1-49a3-bc6e-902305e0e4b3","trusted":true,"_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"raw.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ef52159f-5ad3-4258-ab84-d37a194bbb27","_cell_guid":"4f00def7-9acd-49a8-ae1f-a005873d49ae","trusted":true,"_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"pd.DataFrame(raw.isnull().sum()).T","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f95e36db-f400-4b53-86ec-e15e19d4559e","_cell_guid":"550da578-5c47-45d5-bdf2-80187a491fd0","trusted":true,"_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"\", \".join(raw[\"Country/Region\"].unique().tolist())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"962463b8-db0f-4f2d-b7cd-ea3ccbce8fb7","_cell_guid":"6b5046c3-897d-438e-b483-ae940da47e72","trusted":true,"_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"pprint(raw.loc[raw[\"Country/Region\"] == \"Others\", \"Province/State\"].unique().tolist(), compact=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7b860d14-e603-420a-a655-de2cae2a082e","_cell_guid":"bafa861d-2610-44dd-bd21-2996ccea0d58","trusted":true},"cell_type":"markdown","source":"## Data Cleening: the number of cases\nNote: \"Infected\" = \"Confirmed\" - \"Deaths\" - \"Recovered\""},{"metadata":{"_uuid":"41f0be0f-f8dc-42f7-8773-65dc60f893e5","_cell_guid":"605752b1-4a5c-421c-82a7-d8ae766d893f","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"data_cols = [\"Infected\", \"Deaths\", \"Recovered\"]\nrate_cols = [\"Fatal per Confirmed\", \"Recovered per Confirmed\", \"Fatal per (Fatal or Recovered)\"]\nvariable_dict = {\"Susceptible\": \"S\", \"Infected\": \"I\", \"Recovered\": \"R\", \"Deaths\": \"D\"}","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2988a829-895b-401a-82ae-97d8026b271e","_cell_guid":"d6846623-7a01-4c27-8efc-61ce58d2553c","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"ncov_df = raw.rename({\"ObservationDate\": \"Date\", \"Province/State\": \"Province\"}, axis=1)\nncov_df[\"Date\"] = pd.to_datetime(ncov_df[\"Date\"])\nncov_df[\"Country\"] = ncov_df[\"Country/Region\"].replace(\n    {\n        \"Mainland China\": \"China\",\n        \"Hong Kong SAR\": \"Hong Kong\",\n        \"Taipei and environs\": \"Taiwan\",\n        \"Iran (Islamic Republic of)\": \"Iran\",\n        \"Republic of Korea\": \"South Korea\",\n        \"Republic of Ireland\": \"Ireland\",\n        \"Macao SAR\": \"Macau\",\n        \"Russian Federation\": \"Russia\",\n        \"Republic of Moldova\": \"Moldova\",\n        \"Taiwan*\": \"Taiwan\",\n        \"Cruise Ship\": \"Others\",\n        \"United Kingdom\": \"UK\",\n        \"Viet Nam\": \"Vietnam\",\n        \"Czechia\": \"Czech Republic\",\n        \"St. Martin\": \"Saint Martin\",\n        \"Cote d'Ivoire\": \"Ivory Coast\",\n        \"('St. Martin',)\": \"Saint Martin\",\n        \"Congo (Kinshasa)\": \"Congo\",\n    }\n)\nncov_df[\"Province\"] = ncov_df[\"Province\"].fillna(\"-\").replace(\n    {\n        \"Cruise Ship\": \"Diamond Princess cruise ship\",\n        \"Diamond Princess\": \"Diamond Princess cruise ship\"\n    }\n)\nncov_df[\"Infected\"] = ncov_df[\"Confirmed\"] - ncov_df[\"Deaths\"] - ncov_df[\"Recovered\"]\nncov_df[data_cols] = ncov_df[data_cols].astype(np.int64)\nncov_df = ncov_df.loc[:, [\"Date\", \"Country\", \"Province\", *data_cols]]\nncov_df.tail()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"10e610b6-923a-40b3-955f-e9e5b5bc33a6","_cell_guid":"74d4ce99-e727-4183-b946-88b89a535356","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"ncov_df.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"de5f92d7-6dbb-4fe6-bdec-1f9a724b77a6","_cell_guid":"efb366ae-124b-467d-90ed-60a8280391c5","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"ncov_df.describe(include=\"all\").fillna(\"-\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"faa20bbf-b953-4cb7-af45-beab12cf7c0a","_cell_guid":"58b41156-5c89-47a7-a0dc-ceedc742a9c7","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"pd.DataFrame(ncov_df.isnull().sum()).T","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"513c542b-99ec-4a83-b073-7c70cda0340b","_cell_guid":"e36b6608-3109-4811-ae88-c22d1b47d1a9","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"\", \".join(ncov_df[\"Country\"].unique().tolist())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f8a797b1-fee9-4fd1-8859-9a74cd992bbe","_cell_guid":"8e4e6d71-d916-4a64-95a9-69d4fe2eb02c","trusted":true},"cell_type":"markdown","source":"## Visualize total data except China"},{"metadata":{"_uuid":"44072383-352b-4501-b174-f0ebfef3f95a","_cell_guid":"73d5e052-ebff-4f90-88fb-709637cfb2c4","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"total_df = ncov_df.loc[ncov_df[\"Country\"] != \"China\", :].groupby(\"Date\").sum()\ntotal_df[rate_cols[0]] = total_df[\"Deaths\"] / total_df[data_cols].sum(axis=1)\ntotal_df[rate_cols[1]] = total_df[\"Recovered\"] / total_df[data_cols].sum(axis=1)\ntotal_df[rate_cols[2]] = total_df[\"Deaths\"] / (total_df[\"Deaths\"] + total_df[\"Recovered\"])\ntotal_df.tail()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9c5d84b3-2cd6-42c3-a740-cd84d2c0a52c","_cell_guid":"9fd5240a-1d2b-48ba-8e3d-5e6723af0e8f","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"f\"{(total_df.index.max() - total_df.index.min()).days} days have passed from the date of the first record.\"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"12f82256-a349-49b8-9e17-5ac5bd74f5ae","_cell_guid":"2256ddcb-f67f-4c0a-ba93-6768433fc144","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"line_plot(total_df[data_cols], \"Cases over time (Total except China)\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cace33e4-be48-438a-93ca-d2635ea23189","_cell_guid":"acd0eff2-af43-4859-bb62-af9c7ca10809","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"line_plot(total_df[rate_cols], \"Rate over time (Total except China)\", ylabel=\"\", math_scale=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"79935285-74b5-49f7-a46d-bc191a9d38f2","_cell_guid":"a2318e23-9cf4-495b-8bbf-bcf893898e77","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"total_df[rate_cols].plot.kde()\nplt.title(\"Kernel density estimation of the rates (Total except China)\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"37364cc6-0190-49f7-a554-92b67db8d100","_cell_guid":"bd16187a-99ec-4ec8-8aaf-016fd2b53fd8","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"total_df[rate_cols].describe().T","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1013ce9f-1d5c-4494-86f0-9eac20534b47","_cell_guid":"d1446467-2625-444a-a275-85cbd270eae7","trusted":true},"cell_type":"markdown","source":"## Example of dataset to create math model\n * T means elapsed time [min] from the start date.\n * Susceptible means the patients who are in the area but not infected/recovered/died."},{"metadata":{"_uuid":"5aa008a8-7540-4aa1-8c42-2172fecc8660","_cell_guid":"ed6de24f-9ea0-4208-87e0-7e59f3e900d5","trusted":true},"cell_type":"code","source":"train_start_date, train_df = create_target_df(\n    ncov_df, population_dict[\"Global\"] - population_dict[\"China\"], excluded_places=[(\"China\", None)]\n)\ntrain_start_date.strftime(time_format)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9d7c930f-f14e-432c-86d3-c869081c0b5f","_cell_guid":"1c51c073-8eec-4028-8f02-5e1e7ccef0be","trusted":true},"cell_type":"code","source":"train_df.tail()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"02997bdc-7fd3-49f6-8f23-52b00486d1c4","_cell_guid":"30b580de-bdc0-4051-ae25-1f5e9e8fed2b","trusted":true},"cell_type":"markdown","source":"## Correlation of variables"},{"metadata":{"_uuid":"4b88f6ec-e441-4f54-8c91-d4ec1cb25f2a","_cell_guid":"b2d4756c-fefe-4e98-b02f-aea4a99956e4","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df = train_df.rename(variable_dict, axis=1)\nfor (_, v) in variable_dict.items():\n    df[f\"d{v}/dT\"] = df[v].diff() / df[\"T\"].diff()\n    if v == \"S\":\n        N = population_dict[\"Global\"] - population_dict[\"China\"]\n        df[\"-(dS/dT)*(N/S)\"] = 0 - df[\"S\"].diff() / df[\"T\"].diff() / df[\"S\"] * N\ndf.set_index(\"T\").corr().loc[variable_dict.values(), :].style.background_gradient(axis=None)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"17df7969-64b8-40e2-ad25-53656e6fedb0","_cell_guid":"13594a50-2a92-4e54-a9dc-70486f570ad7","trusted":true},"cell_type":"markdown","source":"* Variables ($I, R, D$) shows high correlation with each other.\n* $-\\mathrm{d}S/\\mathrm{d}T * (N/S)=\\frac{S_{T+\\Delta T} - S_T}{\\Delta T} \\times \\frac{N}{S}$, $\\mathrm{d}I/\\mathrm{d}T=\\frac{I_{T+\\Delta T} - I_T}{\\Delta T}$, $\\mathrm{d}R/\\mathrm{d}T=\\frac{R_{T+\\Delta T} - R_T}{\\Delta T}$ and $\\mathrm{d}D/\\mathrm{d}T=\\frac{D_{T+\\Delta T} - D_T}{\\Delta T}$ show high correlation with I, where N is the total population."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df[[\"I\", \"-(dS/dT)*(N/S)\", \"dI/dT\", \"dR/dT\", \"dD/dT\"]].tail()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c49e21b4-642c-47a0-ab9a-b58c0d12f340","_cell_guid":"8212a969-813e-4107-ac5b-cee5df7bbbbb","trusted":true,"_kg_hide-output":false,"_kg_hide-input":true},"cell_type":"code","source":"sns.lmplot(\n    x=\"I\", y=\"value\", col=\"diff\", sharex=False, sharey=False,\n    data=df[[\"I\", \"-(dS/dT)*(N/S)\", \"dI/dT\", \"dR/dT\", \"dD/dT\"]].melt(id_vars=\"I\", var_name=\"diff\")\n)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data cleaning: Linelist (COVID19_open_line_list.csv)"},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"linelist_open_raw = pd.read_csv(\"/kaggle/input/novel-corona-virus-2019-dataset/COVID19_open_line_list.csv\")\nlinelist_open_raw.info()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"df = linelist_open_raw.loc[:, ~linelist_open_raw.columns.str.startswith(\"Unnamed:\")]\ndf = df.dropna(axis=0, how=\"all\")\ndf = df.drop(\n    [\n        # Unnecessary in this notebook\n        \"ID\", \"wuhan(0)_not_wuhan(1)\", \"admin3\", \"admin2\", \"admin1\", \"country_new\", \"admin_id\",\n        \"data_moderator_initials\", \"source\", \"location\", \"lives_in_Wuhan\", \"notes_for_discussion\",\n        \"sequence_available\", \"reported_market_exposure\",\n        # Maybe useful, but un-used\n        \"city\", \"latitude\", \"longitude\", \"geo_resolution\", \"additional_information\",\n        \"travel_history_dates\", \"travel_history_location\", \n    ],\n    axis=1\n)\n# Personal\nage = linelist_open_raw[\"age\"].str.split(\"-\", expand=True)\nage[0] = pd.to_numeric(age[0], errors=\"coerce\")\nage[1] = pd.to_numeric(age[1], errors=\"coerce\")\ndf[\"Age\"] = age.mean(axis=1)\ndf[\"Age\"] = df[\"Age\"].fillna(df[\"Age\"].median()).astype(np.int64)\ndf[\"Sex\"] = df[\"sex\"].fillna(\"-\").str.replace(\"4000\", \"-\").str.capitalize()\n# Place\ndf[\"Country\"] = df[\"country\"].fillna(\"-\")\ndf[\"Province\"] = df[\"province\"].fillna(\"-\")\n# Onset Date\nseries = df[\"date_onset_symptoms\"].str.replace(\"end of December 2019\", \"31.12.2019\").replace(\"-25.02.2020\", \"25.02.2020\")\nseries = series.replace(\"20.02.220\", \"20.02.2020\").replace(\"none\", np.NaN).replace(\"10.01.2020 - 22.01.2020\", np.NaN)\ndf[\"Onset_date\"] = pd.to_datetime(series)\n# Hospitalized date\nseries = df[\"date_admission_hospital\"].replace(\"18.01.2020 - 23.01.2020\", np.NaN)\ndf[\"Hospitalized_date\"] = pd.to_datetime(series)\n# Confirmed date\nseries = df[\"date_confirmation\"].replace(\"25.02.2020-26.02.2020\", np.NaN)\ndf[\"Confirmed_date\"] = pd.to_datetime(series)\n# Symptoms/events\ndf[\"Symptoms\"] = df[\"symptoms\"].fillna(\"-\").str.lower()\n# Underlying disease\ndf[\"Underlying_disease\"] = df[[\"chronic_disease_binary\", \"chronic_disease\"]].apply(\n    lambda x: \"No\" if x[0] == 0 else x[1] if x[1] is not np.NaN else \"-\",\n    axis=1\n).str.strip(\";\").str.replace(\"; \", \",\").str.replace(\", \", \",\")\n# Outcome\ndf[\"Outcome\"] = df[\"outcome\"].replace(\n    {\n        \"discharge\": \"discharged\", \"Discharged\": \"discharged\", \"death\": \"died\",\n        \"critical condition, intubated as of 14.02.2020\": \"severe\",\n        \"treated in an intensive care unit (14.02.2020)\": \"severe\", \"05.02.2020\": \"-\",\n        \"Symptoms only improved with cough. Currently hospitalized for follow-up.\": \"stable\"\n    }\n).fillna(\"-\")\nseries = df[\"date_death_or_discharge\"].replace(\"discharge\", np.NaN)\ndf[\"Closed_date\"] = pd.to_datetime(series)\n# Show\nuse_cols = [\n    \"Age\", \"Sex\", \"Country\", \"Province\", \"Onset_date\", \"Hospitalized_date\", \"Confirmed_date\", \n    \"Symptoms\", \"Underlying_disease\", \"Outcome\", \"Closed_date\"\n]\nopen_linelist_df = df.loc[:, use_cols]\nopen_linelist_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data cleaning: Linelist (COVID19_line_list_data.csv)\nLinelist in clinical trials is a list of many case reports."},{"metadata":{"_kg_hide-input":false,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"linelist_raw = pd.read_csv(\"/kaggle/input/novel-corona-virus-2019-dataset/COVID19_line_list_data.csv\")\nlinelist_raw.info()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"linelist_raw.head()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"df = linelist_raw.loc[:, ~linelist_raw.columns.str.startswith(\"Unnamed:\")]\ndf = df.drop([\"id\", \"case_in_country\", \"summary\", \"source\", \"link\"], axis=1)\n# Date\ncase_date_dict = {\n    \"reporting date\": \"Confirmed_date\",\n    \"exposure_start\": \"Exposed_date\",\n    \"exposure_end\": \"Quarantined_date\",\n    \"hosp_visit_date\": \"Hospitalized_date\",\n    \"symptom_onset\": \"Onset_date\",\n    \"death\": \"Deaths_date\",\n    \"recovered\": \"Recovered_date\"    \n}\ndf[\"death\"] = df[\"death\"].replace({\"0\": \"\", \"1\": \"\"})\ndf[\"recovered\"] = df[\"recovered\"].replace({\"0\": \"\", \"1\": \"\", \"12/30/1899\": \"12/30/2019\"})\nfor (col, _) in case_date_dict.items():\n    df[col] = pd.to_datetime(df[col])\ndf = df.rename(case_date_dict, axis=1)\n# Location\ndf[\"Country\"] = df[\"country\"].fillna(\"-\")\ndf[\"Province\"] = df[\"location\"].fillna(\"-\")\ndf[\"Province\"] = df[[\"Country\", \"Province\"]].apply(lambda x: \"-\" if x[0] == x[1] else x[1], axis=1)\n# Personal\ndf[\"Gender\"] = df[\"gender\"].fillna(\"-\").str.capitalize()\ndf[\"Age\"] = df[\"age\"].fillna(df[\"age\"].median()).astype(np.int64) ## Fill in NA with median\ndf[\"From_Wuhan\"] = df[\"from Wuhan\"]\ndf[\"To_Wuhan\"] = df[\"visiting Wuhan\"]\n# Medical\ndf[\"Events\"] = df[\"symptom\"].fillna(\"-\")\n# Order of columns\nlinelist_df = df.loc[\n    :,\n    [\n        \"Country\", \"Province\",\n        \"Exposed_date\", \"Onset_date\", \"Hospitalized_date\", \"Confirmed_date\", \"Quarantined_date\", \"Deaths_date\", \"Recovered_date\",\n        \"Events\",\n        \"Gender\", \"Age\", \"From_Wuhan\", \"To_Wuhan\"\n    ]\n]\nlinelist_df.tail()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"linelist_df.info()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"linelist_df.describe(include=\"all\").fillna(\"-\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Trend analysis\nUsing fbprophet package, we will find changing points of log10(comfirmed/deaths/recovered)."},{"metadata":{},"cell_type":"markdown","source":"## Trend of log10(Confirmed)"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"show_trend(ncov_df, variable=\"Confirmed\", excluded_places=[(\"China\", None)])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**No slope change points were found for the number of confirmed cases.**\n<!--**The incline of the number of confirmed cases was slightly grow large on 01Mar2020. I will keep a watchful eye on the trend.**-->"},{"metadata":{},"cell_type":"markdown","source":"## Trend of log10(Deaths)"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"show_trend(ncov_df, variable=\"Deaths\", excluded_places=[(\"China\", None)])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Slope of the number of fatal cases was changed on 04Feb2020. This change was caused by the first report of fatal case.**"},{"metadata":{},"cell_type":"markdown","source":"## Trend of log10(Recovered)"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"show_trend(ncov_df, variable=\"Recovered\", excluded_places=[(\"China\", None)])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**No slope change points were found for the number of recovered cases.**"},{"metadata":{},"cell_type":"markdown","source":"# Improvement of math model\nIn this section, we will create a mathematical model derived from SIR model. The dataset of total except China will be used here as an example."},{"metadata":{"_uuid":"df2ad5db-4dbb-4533-ba9e-d335befe57eb","_cell_guid":"cfcd204a-5677-479e-9362-94c15761a4ac","trusted":true},"cell_type":"markdown","source":"## Prediction with SIR model\nTo understand the trend of infection, we will use mathematical epidemic model. Let's start discussion using a basic model named SIR."},{"metadata":{"_uuid":"12135786-c9e9-49f9-a911-0bc18ee5f596","_cell_guid":"0f8c4e04-c768-4933-b547-92588965dbea","trusted":true},"cell_type":"markdown","source":"### What is SIR model?\nSIR model is a simple mathematical model to understand outbreak of infectious diseases.  \n[The SIR epidemic model - Learning Scientific Programming with Python](https://scipython.com/book/chapter-8-scipy/additional-examples/the-sir-epidemic-model/)\n\n * S: Susceptible (=All - Confirmed)\n * I: Infected (=Confirmed - Recovered - Deaths)\n * R: Recovered or fatal (=Recovered + Deaths)\n \nNote: THIS IS NOT THE GENERAL MODEL!  \nThough R in SIR model is \"Recovered and have immunity\", I defined \"R as Recovered or fatal\". This is because mortality rate cannot be ignored in the real COVID-19 data.\n\nModel:  \nS + I $\\overset{\\beta}{\\longrightarrow}$ 2I  \nI $\\overset{\\gamma}{\\longrightarrow}$ R\n\n$\\beta$: Effective contact rate [1/min]  \n$\\gamma$: Recovery(+Mortality) rate [1/min]  \n\nOrdinary Differential Equation (ODE):   \n$\\frac{\\mathrm{d}S}{\\mathrm{d}T}= - N^{-1}\\beta S I$  \n$\\frac{\\mathrm{d}I}{\\mathrm{d}T}= N^{-1}\\beta S I - \\gamma I$  \n$\\frac{\\mathrm{d}R}{\\mathrm{d}T}= \\gamma I$  \n\nWhere $N=S+I+R$ is the total population, $T$ is the elapsed time from the start date."},{"metadata":{"_uuid":"769f133b-0a3a-4779-a15b-f199a2a3a411","_cell_guid":"58bc8d44-4df3-49fb-85c0-d01a804accc1","trusted":true},"cell_type":"markdown","source":"### Non-dimensional SIR model\nTo simplify the model, we will remove the units of the variables from ODE.\n\nSet $(S, I, R) = N \\times (x, y, z)$ and $(T, \\beta, \\gamma) = (\\tau t, \\tau^{-1} \\rho, \\tau^{-1} \\sigma)$.  \n\nThis results in the ODE  \n$\\frac{\\mathrm{d}x}{\\mathrm{d}t}= - \\rho x y$  \n$\\frac{\\mathrm{d}y}{\\mathrm{d}t}= \\rho x y - \\sigma y$  \n$\\frac{\\mathrm{d}z}{\\mathrm{d}t}= \\sigma y$  \n\nWhere $N$ is the total population and $\\tau$ is a coefficient ([min], is an integer to simplify).  \n\nThe range of variables and parameters:  \n$0 < (x, y, z, \\rho, \\sigma) < 1$  \n$1\\leq \\tau \\leq 1440$  \n\nBasic reproduction number, Non-dimentional parameter, is defined as  \n$R_0 = \\rho \\sigma^{-1} = \\beta \\gamma^{-1}$  \n\nEstimated Mean Values of $R_0$:  \n$R_0$ means \"the average number of secondary infections caused by an infected host\" ([Infection Modeling — Part 1](https://towardsdatascience.com/infection-modeling-part-1-87e74645568a)).  \n(Secondary data: [Van den Driessche, P., & Watmough, J. (2002).](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6002118))  \n2.06: Zika in South America, 2015-2016  \n1.51: Ebola in Guinea, 2014  \n1.33: H1N1 influenza in South Africa, 2009  \n3.5 : SARS in 2002-2003  \n1.68: H2N2 influenza in US, 1957  \n3.8 : Fall wave of 1918 Spanish influenza in Genova  \n1.5 : Spring wave of 1918 Spanish influenza in Genova  \n\nWhen $x=\\frac{1}{R_0}$, $\\frac{\\mathrm{d}y}{\\mathrm{d}t}=0$. This means that the max value of confirmed ($=y+z$) is $1-\\frac{1}{R_0}$."},{"metadata":{"_uuid":"5944df9d-9a62-47a4-b5ad-78934aead04b","_cell_guid":"b52b5d34-5e57-4107-987e-625f818de903","trusted":true},"cell_type":"code","source":"train_dataset = SIR.create_dataset(\n    ncov_df, population_dict[\"Global\"] - population_dict[\"China\"], excluded_places=[(\"China\", None)]\n)\ntrain_start_date, train_initials, train_Tend, train_df = train_dataset\npprint([train_start_date.strftime(time_format), train_initials, train_Tend])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c18c2dd7-b7a7-46ad-b5e7-bc23988843e1","_cell_guid":"1bf56cbc-5386-4e51-a3e2-2d1d3885eb0f","trusted":true},"cell_type":"code","source":"train_df.tail()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"548ebcec-8e51-454c-90c7-a4872487bdbc","_cell_guid":"1a6dd31a-d462-47cf-a177-fd742f53d93e","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"line_plot(\n    train_df.set_index(\"T\").drop(\"x\", axis=1),\n    \"Training data: y(T), z(T)\", math_scale=False, ylabel=\"\"\n)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9c541959-9c0e-4c02-9e70-389226457469","_cell_guid":"e3c1fb34-fe2d-4a34-9e60-ec7f45df8970","trusted":true},"cell_type":"markdown","source":"**Note: We cannot convert $T$ to $t$ because $\\tau$ has not been determined yet.**"},{"metadata":{"_uuid":"e64fc4d7-785a-46e5-95e4-c0d98ab7406a","_cell_guid":"ed7f7e66-b59e-48ec-a72b-a709c3ac9ba8","trusted":true},"cell_type":"markdown","source":"### Example of non-dimensional SIR model\nFor example, set $R_0 = 2.5, \\rho=0.2$."},{"metadata":{"_uuid":"dc79d91a-c375-425a-abdf-f076b9a9e85f","_cell_guid":"9b9b266d-cbbf-40e7-a3a4-6dacc93a4d15","trusted":true},"cell_type":"code","source":"eg_r0, eg_rho = (2.5, 0.2)\neg_sigma = eg_rho / eg_r0\n(eg_rho, eg_sigma)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"121b3dd1-c224-4326-bede-80b33cebd9d1","_cell_guid":"ee3ee9aa-4f12-4da7-b020-c2b957dfeee9","trusted":true},"cell_type":"code","source":"%%time\neg_df = simulation(SIR, train_initials, step_n=300, rho=eg_rho, sigma=eg_sigma)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"eg_df.tail()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f122114e-f47d-4333-9ffd-6a4a688583fe","_cell_guid":"b5412f17-29a7-43a2-ac5b-e013db3047cf","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"line_plot(\n    eg_df.set_index(\"t\"),\n    title=r\"SIR: $R_0$={0} ($\\rho$={1}, $\\sigma$={2})\".format(eg_r0, eg_rho, eg_sigma),\n    ylabel=\"\",\n    h=1\n)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c8b29187-d69a-4ca8-b85f-40e9403cbcad","_cell_guid":"57f7a183-3f1e-408a-b080-5913bdcb5d29","trusted":true},"cell_type":"markdown","source":"### Test of hyperparameter optimization using example data\nTo test the hyperparameter optimization functions defeined in this notebook, we will estimate the SIR model parameters using the example data and example $\\tau=1440$ [min] and total population 1,000,000."},{"metadata":{"_uuid":"0b4e853a-35fc-42e5-a8d4-2ad05cc85278","_cell_guid":"2e03f933-96e9-4507-ba3d-8719278eb04e","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# Set the example conditions\neg_tau = 1440\neg_start_date = ncov_df[\"Date\"].min()\neg_total_population = 1000000\n# Create dataset in the format of ncov_df\neg_ori_df = pd.DataFrame(\n    {\n        \"Date\": (eg_df[\"t\"] * eg_tau).apply(lambda x: timedelta(minutes=x)) + eg_start_date,\n        \"Country\": \"Example\",\n        \"Province\": \"Example\"\n    }\n)\neg_ori_df[\"Infected\"] = (eg_df[\"y\"] * eg_total_population).astype(np.int64)\neg_ori_df[\"Deaths\"] = (eg_df[\"z\"] * eg_total_population * 0.02).astype(np.int64)\neg_ori_df[\"Recovered\"] = (eg_df[\"z\"] * eg_total_population * 0.98).astype(np.int64)\neg_ori_df.tail()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cb75b073-f877-478f-b882-23656efaeedd","_cell_guid":"4fa0ca3e-1826-4b5f-9dc9-a115904662a4","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# line_plot(eg_ori_df.set_index(\"Date\")[data_cols], \"Example data\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f7d9ae2b-fc89-45c6-aa8c-7343e6f7cbcb","_cell_guid":"3491e47b-9205-4c4f-9bf4-37fb1c181fb4","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# %%time\n# eg_sir_estimator = Estimator(SIR, eg_ori_df, eg_total_population, places=[(\"Example\", \"Example\")])\n# eg_sir_dict = eg_sir_estimator.run()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7299c718-bd29-4315-a4c7-40123130c6ad","_cell_guid":"9637dfc3-c893-42a4-970f-8dd00a45a479","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# eg_sir_estimator.compare_graph()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c2319409-ff8c-41e3-a6e9-381dc88e4b6d","_cell_guid":"334627c9-18e5-420a-8b5f-07907a7336a9","trusted":true,"_kg_hide-output":false,"_kg_hide-input":true},"cell_type":"code","source":"\"\"\"\neg_dict = {\n    \"Condition\": {\n        \"tau\": eg_tau, \"rho\": eg_rho, \"sigma\": eg_sigma,\n        \"R0\": eg_r0, \"score\": 0, **SIR(rho=eg_rho, sigma=eg_sigma).calc_days_dict(eg_tau)\n    },\n    \"Estimation\": eg_sir_dict\n}\ndf = pd.DataFrame.from_dict(eg_dict, orient=\"index\")\ndf\n\"\"\"\nNone","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cccab605-b3b6-4a5a-899a-73805d4534b7","_cell_guid":"e7a47791-1e6c-44cc-a8fb-7f14973a4810","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# eg_sir_estimator.predict_graph(step_n=500, name=\"Example area\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f800c639-c717-4276-87f5-06ef85689cb3","_cell_guid":"f0c58fc7-4c1e-432f-a687-23ed230544e6","trusted":true},"cell_type":"markdown","source":"### Hyperparameter optimization\nUsing Optuna package, ($\\rho, \\sigma, \\tau$) will be estimated by model fitting."},{"metadata":{"_uuid":"76193d22-6038-4ec4-91c8-b0a8f2385682","_cell_guid":"efa28bae-2968-43cb-9952-eb1127deafe7","trusted":true},"cell_type":"code","source":"%%time\nsir_estimator = Estimator(\n    SIR, ncov_df, population_dict[\"Except China\"],\n    name=\"Except China\", excluded_places=[(\"China\", None)]\n)\nsir_dict = sir_estimator.run()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c7d9de06-0f3e-4bf2-bc97-98c7f5f49089","_cell_guid":"ad5d4ac6-93e3-4572-b77d-76fe2d66e47a","trusted":true},"cell_type":"code","source":"sir_estimator.history_df().head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"66e85f18-788a-4924-a77c-a19439bc6305","_cell_guid":"bbbbd935-ccfb-4382-bba7-c1db09efbc32","trusted":true},"cell_type":"code","source":"sir_estimator.history_graph()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d61b89d3-50a7-4c6c-843b-a0fbd5f7f15a","_cell_guid":"cf8d9a7b-8dae-48f9-91de-720d80b4111a","trusted":true},"cell_type":"code","source":"pd.DataFrame.from_dict({\"SIR\": sir_dict}, orient=\"index\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"79de7c4a-c2e2-41b1-b67b-f0539e0b3c94","_cell_guid":"c143a264-6b3e-4956-b542-4de0239897dc","trusted":true},"cell_type":"code","source":"sir_estimator.compare_graph()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3a19da1b-6448-4b50-b392-d9cd57dc539f","_cell_guid":"fffc6a43-34c8-4475-9ae6-bd377050f1c1","trusted":true},"cell_type":"code","source":"sir_estimator.predict_graph(step_n=400)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"abc5f4a0-5674-4678-938b-79db83e4f4f5","_cell_guid":"6ad03ba6-eaba-41ea-b816-17962a58bd54","trusted":true},"cell_type":"markdown","source":"## Prediction with SIR-D model\nBecause we can measure the number of fatal cases and recovered cases separately, we can use two variables (\"Recovered\" and \"Deaths\") instead of \"Recovered + Deaths\" in the mathematical model."},{"metadata":{"_uuid":"ac79b973-cdd3-4beb-825d-c29f987f6cd1","_cell_guid":"54813702-3d5a-4aeb-89dc-b7b5014fb9fb","trusted":true},"cell_type":"markdown","source":"### What is SIR-D model?\n* S: Susceptible\n* I: Infected\n* R: Recovered\n* D: Fatal\n\nModel:  \nS + I $\\overset{\\beta}{\\longrightarrow}$ 2I  \nI $\\overset{\\gamma}{\\longrightarrow}$ R  \nI $\\overset{\\alpha}{\\longrightarrow}$ D  \n\n$\\alpha$: Mortality rate [1/min]  \n$\\beta$: Effective contact rate [1/min]  \n$\\gamma$: Recovery rate [1/min]  \n\nOrdinary Differential Equation (ODE):   \n$\\frac{\\mathrm{d}S}{\\mathrm{d}T}= - N^{-1}\\beta S I$  \n$\\frac{\\mathrm{d}I}{\\mathrm{d}T}= N^{-1}\\beta S I - (\\gamma + \\alpha) I$  \n$\\frac{\\mathrm{d}R}{\\mathrm{d}T}= \\gamma I$  \n$\\frac{\\mathrm{d}D}{\\mathrm{d}T}= \\alpha I$  \n\nWhere $N=S+I+R+D$ is the total population, $T$ is the elapsed time from the start date."},{"metadata":{"_uuid":"20008d93-6fef-4053-af91-aef177eed421","_cell_guid":"b3cbf5d5-c269-4695-8835-46ed417d9c48","trusted":true},"cell_type":"markdown","source":"### Non-dimensional SIR-D model\nSet $(S, I, R, D) = N \\times (x, y, z, w)$ and $(T, \\alpha, \\beta, \\gamma) = (\\tau t, \\tau^{-1} \\kappa, \\tau^{-1} \\rho, \\tau^{-1} \\sigma)$.  \nThis results in the ODE  \n$\\frac{\\mathrm{d}x}{\\mathrm{d}t}= - \\rho x y$  \n$\\frac{\\mathrm{d}y}{\\mathrm{d}t}= \\rho x y - (\\sigma + \\kappa) y$  \n$\\frac{\\mathrm{d}z}{\\mathrm{d}t}= \\sigma y$  \n$\\frac{\\mathrm{d}w}{\\mathrm{d}t}= \\kappa y$  \n\nWhere $N$ is the total population and $\\tau$ is a coefficient ([min], is an integer to simplify).  \n\nThe range of variables and parameters:  \n$0 < (x, y, z, w, \\kappa, \\rho, \\sigma) < 1$  \n$1\\leq \\tau \\leq 1440$\n\nReproduction number can be defined as  \n$R_0 = \\rho (\\sigma + \\kappa)^{-1} = \\beta (\\gamma + \\alpha)^{-1}$"},{"metadata":{"_uuid":"71f0c51c-dc0e-4b7d-8a00-047dffd01486","_cell_guid":"017ea3f3-b6ca-4bba-8169-bdfdc7f62b8f","trusted":true},"cell_type":"markdown","source":"### Hyperparameter optimization\nUsing Optuna package, ($\\kappa, \\rho, \\sigma, \\tau$) will be estimated by model fitting."},{"metadata":{"_uuid":"c00c15a8-b4aa-44d5-a636-5394d8126ec6","_cell_guid":"6599a692-714f-45db-85cc-e9e44949ac5b","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# %%time\n# sird_estimator = Estimator(\n#     SIRD, ncov_df, population_dict[\"Except China\"],\n#     name=\"Except China\", excluded_places=[(\"China\", None)],\n#     tau=sir_dict[\"tau\"], rho=sir_dict[\"rho\"]\n# )\n# sird_dict = sird_estimator.run()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7320cf16-e0fa-4bab-b657-1955576864a2","_cell_guid":"d74f4e98-d5cc-402d-af7e-61bb976678a0","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# sird_estimator.history_graph()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c2260b29-feac-4c56-9a2f-5d6282cead68","_cell_guid":"bf0c3019-c018-4687-a6b8-c5504a5861fc","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# pd.DataFrame.from_dict({\"SIR\": sir_dict, \"SIR-D\": sird_dict}, orient=\"index\").fillna(\"-\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f652817d-86bb-45a0-9cbf-c15657a7e13d","_cell_guid":"fd03e9b2-16ff-4047-8590-4db421b39fa1","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# sird_estimator.compare_graph()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7e89bd60-23ce-4feb-a773-349324eeac29","_cell_guid":"3d02748c-68ca-4ea3-979c-40c5ca1638b4","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# sird_estimator.predict_graph(step_n=500)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b17a61ed-d8da-43ba-b028-1949760dc0ca","_cell_guid":"c19b122a-84fb-4757-834e-bb72002cdfb3","trusted":true},"cell_type":"markdown","source":"## Prediction with SIR-F model\nSome cases are reported as fatal cases before clinical diagnosis of COVID-19. To consider this issue, \"S + I $\\to$ Fatal + I\" will be added to the model."},{"metadata":{"_uuid":"3f40d0e2-7fb1-4082-8308-e27d37efc943","_cell_guid":"0a2eafd9-5355-4953-af46-025e6554fa59","trusted":true},"cell_type":"markdown","source":"### What is SIR-F model?\n* S: Susceptible\n* S$^\\ast$: Confirmed and un-categorized\n* I: Confirmed and categorized as I\n* R: Recovered\n* F: Fatal with confirmation\n\nMeasurable variables:  \nConfirmed = $I+R+F$  \nRecovered = $R$  \nDeaths = $F$  \n\nModel:  \nS $\\overset{\\beta \\mathrm{I}}{\\longrightarrow}$ S$^\\ast$ $\\overset{\\alpha_1}{\\longrightarrow}$ F  \nS $\\overset{\\beta \\mathrm{I}}{\\longrightarrow}$ S$^\\ast$ $\\overset{1 - \\alpha_1}{\\longrightarrow}$ I  \nI $\\overset{\\gamma}{\\longrightarrow}$ R  \nI $\\overset{\\alpha_2}{\\longrightarrow}$ F  \n\n$\\alpha_1$: Mortality rate of S$^\\ast$ cases [-]  \n$\\alpha_2$: Mortality rate of I cases [1/min]  \n$\\beta$: Effective contact rate [1/min]  \n$\\gamma$: Recovery rate [1/min]  \n\nOrdinary Differential Equation (ODE):   \n$\\frac{\\mathrm{d}S}{\\mathrm{d}T}= - N^{-1}\\beta S I$  \n$\\frac{\\mathrm{d}I}{\\mathrm{d}T}= N^{-1}(1 - \\alpha_1) \\beta S I - (\\gamma + \\alpha_2) I$  \n$\\frac{\\mathrm{d}R}{\\mathrm{d}T}= \\gamma I$  \n$\\frac{\\mathrm{d}F}{\\mathrm{d}T}= N^{-1}\\alpha_1 \\beta S I + \\alpha_2 I$  \n\nWhere $N=S+I+R+F$ is the total population, $T$ is the elapsed time from the start date."},{"metadata":{"_uuid":"1a5a19e0-d71a-409b-902e-707d2afe8249","_cell_guid":"fa88a43d-671a-4109-8d60-8b2cacebed68","trusted":true},"cell_type":"markdown","source":"### Non-dimensional SIR-F model\nSet $(S, I, R, F) = N \\times (x, y, z, w)$ and $(T, \\alpha_1, \\alpha_2, \\beta, \\gamma) = (\\tau t, \\theta, \\tau^{-1} \\kappa, \\tau^{-1} \\rho, \\tau^{-1} \\sigma)$.  \nThis results in the ODE  \n$\\frac{\\mathrm{d}x}{\\mathrm{d}t}= - \\rho x y$  \n$\\frac{\\mathrm{d}y}{\\mathrm{d}t}= \\rho (1-\\theta) x y - (\\sigma + \\kappa) y$  \n$\\frac{\\mathrm{d}z}{\\mathrm{d}t}= \\sigma y$  \n$\\frac{\\mathrm{d}w}{\\mathrm{d}t}= \\rho \\theta x y + \\kappa y$  \n\nWhere $N$ is the total population and $\\tau$ is a coefficient ([min], is an integer to simplify).  \n\nThe range of variables and parameters:  \n$0 < (x, y, z, w, \\theta, \\kappa, \\rho, \\sigma) < 1$  \n$1 \\leq \\tau \\leq 1440$  \n\nReproduction number can be defined as  \n$R_0 = \\rho (1 - \\theta) (\\sigma + \\kappa)^{-1} = \\beta (1 - \\alpha_1) (\\gamma + \\alpha_2)^{-1}$"},{"metadata":{"_uuid":"3312c5a7-3ce0-41f1-bc8b-67da61091c70","_cell_guid":"9ad0cd56-fc56-495c-8e4e-698931fd756f","trusted":true},"cell_type":"markdown","source":"### Hyperparameter optimization\nUsing Optuna package, ($\\theta, \\kappa, \\rho, \\sigma, \\tau$) will be estimated by model fitting."},{"metadata":{"_uuid":"177c29e4-93fa-4fae-864a-77a952f818ad","_cell_guid":"9e90ff6d-2612-4fa1-bc3d-0dae73843f44","trusted":true},"cell_type":"code","source":"%%time\nsirf_estimator = Estimator(\n    SIRF, ncov_df, population_dict[\"Except China\"],\n    name=\"Except China\", excluded_places=[(\"China\", None)],\n    tau=sir_dict[\"tau\"]\n)\nsirf_dict = sirf_estimator.run()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"sirf_estimator.history_df().head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b11aeb29-afd0-4378-8574-d5124b821ea0","_cell_guid":"75abc8cf-b898-4d9f-b30c-e8e403626447","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"sirf_estimator.history_graph()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"375cb268-d100-4c5b-8f7a-fa3aeb9f319e","_cell_guid":"13b5989d-1ea6-4dae-812e-e5b0ce735c5f","trusted":true},"cell_type":"code","source":"pd.DataFrame.from_dict({\"SIR\": sir_dict, \"SIR-F\": sirf_dict}, orient=\"index\").fillna(\"-\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8a15a081-716a-4638-907a-60330536b1ef","_cell_guid":"eb91e6c8-7df1-4c50-8765-05f5375f4099","trusted":true},"cell_type":"code","source":"sirf_estimator.compare_graph()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"82cac758-9303-43f5-bd76-5113010cbd12","_cell_guid":"1de174a0-fbaf-4951-bd78-d7071b5ceda4","trusted":true},"cell_type":"code","source":"sirf_estimator.predict_graph(step_n=500)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8e518ca6-e518-402b-b7f1-09ceabf898ad","_cell_guid":"c6ecf5ad-5656-4dd5-bf4f-98aae18c6d5a","trusted":true},"cell_type":"markdown","source":"# SIR-F model at country level"},{"metadata":{"_uuid":"e966fca4-3867-48ce-a802-ec89476f389b","_cell_guid":"c57f89dd-d973-430b-a609-6e9f01dce25d","trusted":true},"cell_type":"markdown","source":"## Compare country raw data except China"},{"metadata":{"_uuid":"4b6528ca-1fc0-4518-9f1c-ce549a3b4cd7","_cell_guid":"ae36df05-7c0c-4f1c-9b2d-04c2b6cfc842","trusted":true},"cell_type":"code","source":"country_df = ncov_df.pivot_table(\n    values=\"Infected\", index=\"Date\", columns=\"Country\", aggfunc=sum\n).fillna(0).astype(np.int64)\ncountry_df = country_df.drop(\"China\", axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3aa0a74f-f7e3-4d4c-9e97-cdede9ee4e96","_cell_guid":"7bd33319-9b8d-48ad-8776-2d6f7d2cdd42","trusted":true},"cell_type":"code","source":"line_plot(\n    country_df.T.nlargest(10, country_df.index.max()).T,\n    \"Infected in top 5 countries except China\",\n    math_scale=False\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Japan"},{"metadata":{"trusted":true},"cell_type":"code","source":"show_trend(ncov_df, variable=\"Confirmed\", places=[(\"Japan\", None)])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We will use data after 16Feb2020.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"jp_start = \"16Feb2020\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_, jp_df = create_target_df(ncov_df, population_dict[\"Japan\"], places=[(\"Japan\", None)], start_date=jp_start)\nline_plot(jp_df.set_index(\"T\")[data_cols], f\"Japan: without Susceptible after {jp_start}\", math_scale=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\njp_estimator = Estimator(\n    SIRF, ncov_df, population_dict[\"Japan\"], name=\"Japan\", places=[(\"Japan\", None)],\n    start_date=jp_start\n)\njp_dict = jp_estimator.run()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"jp_estimator.compare_graph()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"jp_estimator.predict_graph(step_n=1200)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c2dc7ab9-b735-439a-913a-b2794fef2ced","_cell_guid":"ea22184d-b5c0-4d2e-807b-5e68e08a1c31","trusted":true},"cell_type":"markdown","source":"## South Korea"},{"metadata":{"trusted":true},"cell_type":"code","source":"show_trend(ncov_df, variable=\"Confirmed\", places=[(\"South Korea\", None)])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eb8d4776-aade-43c0-800a-0920ddbafe10","_cell_guid":"4a0d218e-8511-4fd3-a173-e615b9e2fa3f","trusted":true},"cell_type":"markdown","source":"**We will use data after 22Feb2020. \"Infected\" suddenly arised after 18Feb2020 (especially in Church of Jesus in Daegu).**"},{"metadata":{"trusted":true},"cell_type":"code","source":"sk_start = \"22Feb2020\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sk_start_date, sk_df = create_target_df(\n    ncov_df, population_dict[\"South Korea\"], places=[(\"South Korea\", None)], start_date=sk_start\n)\nline_plot(sk_df.set_index(\"T\")[data_cols], f\"South Korea: without Susceptible after {sk_start}\", math_scale=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2399b743-9522-49bb-b55d-25678e11fde7","_cell_guid":"aebf1b4e-d68d-40d1-985f-0b2be9378ac6","trusted":true},"cell_type":"code","source":" %%time\n sk_estimator = Estimator(\n     SIRF, ncov_df, population_dict[\"South Korea\"], name=\"South Korea\", places=[(\"South Korea\", None)],\n     start_date=sk_start\n)\n sk_dict = sk_estimator.run()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"06de9664-9500-4589-bf4a-0508eca7f972","_cell_guid":"bb7fc6aa-0d96-42e4-ad93-2c864596a3a5","trusted":true},"cell_type":"code","source":" sk_estimator.compare_graph()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6c317375-19ed-4501-9a12-b98895635de2","_cell_guid":"eef29875-68c7-4d89-bb0e-ca44c66e6542","trusted":true},"cell_type":"code","source":" sk_estimator.predict_graph(step_n=int(4000 / sk_dict[\"tau\"]))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f9f78408-4ea0-456a-ae4c-eadec9ab1a88","_cell_guid":"afd88f5d-b32a-4612-8596-8d8ac727ffc7","trusted":true},"cell_type":"markdown","source":"## Iran"},{"metadata":{"trusted":true},"cell_type":"code","source":"show_trend(ncov_df, variable=\"Confirmed\", places=[(\"Iran\", None)])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**In Iran, the slope is slightly changed on 27Feb2020 and 07Mar2020. We will use all data because the reasons are unclear.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"ir_start = ncov_df.loc[ncov_df[\"Country\"] == \"Iran\", \"Date\"].min().strftime(\"%d%b%Y\")\nir_start","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"61cc274c-0976-4b2b-a1dd-b923244edb92","_cell_guid":"fbdcd097-88d6-44c4-b3e5-5171a34fe54e","trusted":true},"cell_type":"code","source":"_, ir_df = create_target_df(\n    ncov_df, population_dict[\"Iran\"], places=[(\"Iran\", None)], start_date=ir_start\n)\nline_plot(ir_df.set_index(\"T\")[data_cols], f\"Iran: without Susceptible after {ir_start}\", math_scale=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"787ab83e-ffb0-446f-9e88-0909c8f2efd3","_cell_guid":"6bba62ea-d5f8-4474-80c4-3f63a337e1f1","trusted":true},"cell_type":"code","source":"%%time\nir_estimator = Estimator(\n    SIRF, ncov_df, population_dict[\"Iran\"], name=\"Iran\", places=[(\"Iran\", None)],\n    start_date=ir_start\n)\nir_dict = ir_estimator.run()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3cafc31c-492f-4f42-ba31-8ec7ae9b95ce","_cell_guid":"4184660e-f5f8-4466-b35c-609324f51686","trusted":true},"cell_type":"code","source":"ir_estimator.compare_graph()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f62746d5-6d58-4bc7-934c-36d09af4ff37","_cell_guid":"6ed7ff32-8319-4857-bdbd-3e707014f61e","trusted":true},"cell_type":"code","source":"ir_estimator.predict_graph(step_n=500)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ITALY"},{"metadata":{"trusted":true},"cell_type":"code","source":"show_trend(ncov_df, variable=\"Confirmed\", places=[(\"Italy\", None)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"it_start = \"20Feb2020\"\nit_estimator = Estimator(\n    SIRF, ncov_df, population_dict[\"Italy\"], name=\"Italy\", places=[(\"Italy\", None)],\n    start_date=it_start\n)\nit_dict = it_estimator.run()\nit_estimator.compare_graph()\nit_estimator.predict_graph(step_n=1200)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**UNITED STATES**"},{"metadata":{"trusted":true},"cell_type":"code","source":"show_trend(ncov_df, variable=\"Confirmed\", places=[(\"US\", None)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"us_start = \"01Feb2020\"\nus_estimator = Estimator(\n    SIRF, ncov_df, population_dict[\"US\"], name=\"US\", places=[(\"US\", None)],\n    start_date=us_start\n)\nus_dict = us_estimator.run()\nus_estimator.compare_graph()\nus_estimator.predict_graph(step_n=1200)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"first_model, info_dict, param_dict = us_estimator.info()\npredicter = Predicter(**info_dict)\npredicter.add(first_model, end_day_n=350, count_from_last=False, **param_dict)\npredicter.restore_graph(drop_cols=None)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5a829877-1add-4579-be03-10c5d9dc3d74","_cell_guid":"303029b5-bc3b-49f3-b62a-be89b9fb4996","trusted":true},"cell_type":"markdown","source":"## Parameter comparsion of the countries"},{"metadata":{"_uuid":"167153e4-a425-48d3-b980-6dc8711a8089","_cell_guid":"dfb833df-dfe9-44f6-8fa1-fa8b62021e5e","trusted":true},"cell_type":"code","source":"_dict = {\n    \"Except China\": sirf_dict,\n    \"Japan\": jp_dict,\n    \"South Korea\": sk_dict,\n    \"Iran\": ir_dict,\n    \"Italy\": it_dict,\n    \"US\": us_dict,\n}\npd.DataFrame.from_dict(_dict, orient=\"index\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# The number of exposed cases and waiting cases\nThe number of exposed cases in latent period (E) and wating cases for confirmation (W) are un-measurable variables, but key variables as well as S, I, R, F. If E and W are large, outbreak will occur in the near future. Let's replace S $\\overset{\\beta \\mathrm{I}}{\\longrightarrow}$ S$^\\ast$ with S $\\overset{\\beta_1 \\mathrm{(W+I)}}{\\longrightarrow}$ E $\\overset{\\beta_2}{\\longrightarrow}$ W $\\overset{\\beta_3}{\\longrightarrow}$ S$^\\ast$ because W also has infectivity.\n\nNote:  \nW and some rules were added to explain COVID-19 dataset, but this is like-SEIR model.  \nTo study general SEIR-model, please refer to PDF material in [Introduction to SEIR model Models](http://indico.ictp.it/event/7960/session/3/contribution/19/material/slides/)."},{"metadata":{},"cell_type":"markdown","source":"## What is SEWIR-F model?\n* S: Susceptible\n* <u>E: Exposed and in latent period</u>\n* <u>W: Waiting cases for confirmation (with infectivity)</u>\n* S$^\\ast$: Confirmed and un-categorized\n* I: Confirmed and categorized as I\n* R: Recovered\n* F: Fatal with confirmation\n\nMeasurable variables:  \nTotal population - Confirmed = $S+E+W+S^\\ast$  \nConfirmed = $I+R+F$  \nRecovered = $R$  \nDeaths = $F$  \n\nModel:  \nS $\\overset{\\beta_1 \\mathrm{(W+I)}}{\\longrightarrow}$ E $\\overset{\\beta_2}{\\longrightarrow}$ W $\\overset{\\beta_3}{\\longrightarrow}$ S$^\\ast$ $\\overset{\\alpha_1}{\\longrightarrow}$ F  \nS $\\overset{\\beta_1 \\mathrm{(W+I)}}{\\longrightarrow}$ E $\\overset{\\beta_2}{\\longrightarrow}$ W $\\overset{\\beta_3}{\\longrightarrow}$ S$^\\ast$ $\\overset{1 - \\alpha_1}{\\longrightarrow}$ I  \nI $\\overset{\\gamma}{\\longrightarrow}$ R  \nI $\\overset{\\alpha_2}{\\longrightarrow}$ F  \n\n$\\alpha_1$: Mortality rate of S$^\\ast$ cases [-]  \n$\\alpha_2$: Mortality rate of I cases [1/min]  \n$\\beta_1$: <u>Exposure rate (the number of encounter with the virus in a minute)</u> [1/min]  \n$\\beta_2$: <u>Inverse of latent period</u> [1/min]  \n$\\beta_3$: <u>Inverse of waiting time for confirmation</u> [1/min]  \n$\\gamma$: Recovery rate [1/min]  \n\nOrdinary Differential Equation (ODE):   \n$\\frac{\\mathrm{d}S}{\\mathrm{d}T}= - N^{-1}\\beta_1 S (W + I)$  \n$\\frac{\\mathrm{d}E}{\\mathrm{d}T}= N^{-1}\\beta_1 S (W + I) - \\beta_2 E$  \n$\\frac{\\mathrm{d}W}{\\mathrm{d}T}= \\beta_2 E - \\beta_3 W$  \n$\\frac{\\mathrm{d}I}{\\mathrm{d}T}= (1 - \\alpha_1)\\beta_3 W - (\\gamma + \\alpha_2) I$  \n$\\frac{\\mathrm{d}R}{\\mathrm{d}T}= \\gamma I$  \n$\\frac{\\mathrm{d}F}{\\mathrm{d}T}= N^{-1}\\alpha_1 \\beta_2 E + \\alpha_2 I$  \n\nWhere $N=S+E+W+I+R+F$ is the total population, $T$ is the elapsed time from the start date."},{"metadata":{},"cell_type":"markdown","source":"## Non-dimensional SEIR-F model\nSet $(S, E, W, I, R, F) = N \\times (x_1, x_2, x_3, y, z, w)$, $(T, \\alpha_1) = (\\tau t, \\theta)$ and $(\\alpha_2, \\beta_i, \\gamma) = \\tau^{-1} \\times (\\kappa, \\rho_i, \\sigma)$.  \nThis results in the ODE  \n$\\frac{\\mathrm{d}x_1}{\\mathrm{d}t}= - \\rho_1 x_1 (x_3 + y)$  \n$\\frac{\\mathrm{d}x_2}{\\mathrm{d}t}= \\rho_1 x_1 (x_3 + y) - \\rho_2 x_2$  \n$\\frac{\\mathrm{d}x_3}{\\mathrm{d}t}= \\rho_2 x_2 - \\rho_3 x_3$  \n$\\frac{\\mathrm{d}y}{\\mathrm{d}t}= (1-\\theta) \\rho_3 x_3 - (\\sigma + \\kappa) y$  \n$\\frac{\\mathrm{d}z}{\\mathrm{d}t}= \\sigma y$  \n$\\frac{\\mathrm{d}w}{\\mathrm{d}t}= \\theta \\rho_2 x_2 + \\kappa y$  \n\nWhere $N$ is the total population and $\\tau$ is a coefficient ([min], is an integer to simplify).  \n\nThe range of variables and parameters:  \n$0 < (x_i, y, z, w, \\theta, \\kappa, \\rho_i, \\sigma) < 1$  \n$1 \\leq \\tau \\leq 1440$  \n\nReproduction number can be defined as  \n$R_0 = \\rho_1 (1-\\theta) (\\sigma + \\kappa)^{-1}$"},{"metadata":{},"cell_type":"markdown","source":"## Calculate $\\rho_2$ and $\\rho_3$\nTo estimate $\\rho_2=\\tau \\beta_2$ and $\\rho_3=\\tau \\beta_3$, we first calculate median value of latent period $\\overline{L_E}$ and waiting time for confirmation $\\overline{L_W}$ using linelist. We assume that patients start to have infectivity from onset dates. This means latent period is equal to incubation period.\n\n$\\beta_2$: Inverse of latent period [1/min]  \n$\\beta_3$: Inverse of waiting time for confirmation [1/min]  "},{"metadata":{"trusted":true},"cell_type":"code","source":"period_df = select_area(linelist_df, excluded_places=[(\"China\", None)], group=None)\nperiod_df = period_df.loc[:, [\"Exposed_date\", \"Onset_date\", \"Confirmed_date\"]]\nperiod_df[\"Latent [min]\"] = (period_df[\"Onset_date\"] - period_df[\"Exposed_date\"]).dt.total_seconds() / 60\nperiod_df[\"Waiting [min]\"] = (period_df[\"Confirmed_date\"] - period_df[\"Onset_date\"]).dt.total_seconds() / 60\nperiod_df[\"Latent [day]\"] = period_df[\"Latent [min]\"] / 60 / 24\nperiod_df[\"Waiting [day]\"] = period_df[\"Waiting [min]\"] / 60 / 24\nperiod_df[\"Latent + Waiting [day]\"] = period_df[\"Latent [day]\"] + period_df[\"Waiting [day]\"]\nperiod_df.dropna(axis=0).tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = [\"Latent [day]\", \"Waiting [day]\", \"Latent + Waiting [day]\"]\nperiod_df[cols].plot.kde()\nplt.title(\"Kernel density estimation of latent period and waiting time for confirmation [day]\")\nplt.show()\nperiod_df[cols].describe().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"latent_period = period_df[\"Latent [min]\"].median()\nwaiting_time = period_df[\"Waiting [min]\"].median()\ntau = sirf_estimator.info()[1][\"tau\"]\nrho2, rho3 = tau / latent_period, tau / waiting_time\n(rho2, rho3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We will use in scenario analysis section\nlatent_waiting_day = period_df[\"Latent + Waiting [day]\"].median()\nlatent_waiting_day","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Estimate $\\rho_1$\nWe wil estimate $\\rho_1$ using the model and dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"param_dict = sirf_estimator.info()[2]\nparam_dict.pop(\"rho\")\nparam_dict[\"tau\"] = tau\nparam_dict[\"rho2\"] = rho2\nparam_dict[\"rho3\"] = rho3\nparam_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nsewirf_estimator = Estimator(\n    SEWIRF, ncov_df, population_dict[\"Except China\"],\n    name=\"Except China\", excluded_places=[(\"China\", None)],\n    **param_dict\n)\nsewirf_dict = sewirf_estimator.run()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame.from_dict({\"SIR\": sir_dict, \"SIR-F\": sirf_dict, \"SEWIR-F\": sewirf_dict}, orient=\"index\").fillna(\"-\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sewirf_estimator.compare_graph()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Prediction with SEWIR-F model"},{"metadata":{"trusted":true},"cell_type":"code","source":"first_model, info_dict, param_dict = sewirf_estimator.info()\ninfo_dict[\"name\"] = \"Except China\"\npd.DataFrame.from_dict({\"No actions\": param_dict}, orient=\"index\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicter = Predicter(**info_dict)\npredicter.add(SEWIRF, end_day_n=None, count_from_last=False, vline=False, **param_dict)\npredicter.add(SEWIRF, end_day_n=30, count_from_last=True, **param_dict)\npredicter.restore_graph(drop_cols=[\"Susceptible\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicter = Predicter(**info_dict)\npredicter.add(SEWIRF, end_day_n=500, count_from_last=False, **param_dict)\npredicter.restore_graph(drop_cols=None)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Scenario analysis\nTo figure out what to do for minimizing the damage, we will perform scenario analysis in this section. \n* Suggest real factors of the parameters of the math model\n* Collect/predict records of the real factors\n* Calcurate the impact of actions on the parameters\n* Predict the future in the assumption that new actions are taken since today\n* Figure out what to do right now"},{"metadata":{},"cell_type":"markdown","source":"## Real factors of effective contact rate $\\beta_1$\nPlease reconsider S $\\overset{\\beta_1 \\mathrm{(W+I)}}{\\longrightarrow}$ E formula. Susceptible persons may contact with currently infected patients, and susceptible persons will be infected with COVID-19. The formura can be replaced with  \nS$_\\mathrm{q}$ $\\overset{g_{s}}{\\Longleftrightarrow}$ S$_{\\mathrm{g}}$ $\\overset{f_1}{\\longrightarrow}$ E$^\\ast$ $\\overset{e^{-h_2}}{\\longrightarrow}$ E  \nI$_\\mathrm{q}$ $\\overset{g_i}{\\Longleftrightarrow}$ I$_{\\mathrm{g}}$  \nI$_\\mathrm{q}$ $\\overset{q}{\\longrightarrow}$ I$_{\\hat{\\mathrm{q}}}$  \nE$^\\ast$ $\\overset{1-e^{-h_2}}{\\longrightarrow}$ R$^\\ast$\n\n$\\Longleftrightarrow$ (as substitute for $\\longrightarrow$ with $\\longleftarrow$) means that right side can be return to the left side.  \nS$_\\mathrm{q}$: Susceptible persons in quarantine <!--Susceptible in the strict sense-->  \nS$_\\mathrm{g}$: Susceptible persons with family members or friends etc.  \nI$_\\mathrm{q}$: Currently infected patients in quarantine  \nI$_\\mathrm{g}$: Currently infected patients with family members or friends etc.  \nI$_\\hat{\\mathrm{q}}$: Currently infected patients who was hospitalized  \nE$^\\ast$: Just after being exposed to the virus  \nR$^\\ast$: Being exposed to the virus, fighted with the virus, recovered and immuned without confirmation  \n\n$f_1 = vI_{\\mathrm{g}}(1-m)^2(1-w_e)^{w_n}e^{-h_1}sc$ [-] \n\nReal factors:  \n$g_s$: The number of days in <u>a week</u> susceptible persons go out [day]  \n$g_i$: The number of days in <u>a week</u> currently infected (confirmed) but un-quarantined persons go out [day]  \n$q$: Quarantine rate of currently infected (confirmed) patients [-]  \n$v$: Probability of virus existance in a droplet [-]  \n$m$: Rate of persons wearing masks effectively (depends logistically on supply of masks) [-]  \n$w_e$: Virus reduction effect of washing hands [-]  \n$w_n$: The number of times people washes their hands before touching their own faces after go out [-]  \n$h_1$: Health condition (active rate of cellular immunity factors) of susceptible and contacted persons [-]  \n$h_2$: Health condition (active rate of humoral immunity factors) of susceptible and contacted persons [-]  \n$c$: The number of contacts between susceptible persons and patients while on the go in a minute (depends on population density) [1/min]  \n$\\delta$:The product of unknown real factors [-]  \n\nThe parameter in the math model:  \n$\\beta_1 = \\cfrac{g_s g_i (1-q) v (1-m)^2 (1-w_e)^{w_n} e^{-(h_{1}+h_{2})} c \\delta}{49}$ [1/min]\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Value of beta before actions are taken\nbeta1_before = param_dict[\"rho1\"] / info_dict[\"tau\"]\nbeta1_before","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### $g_s$ value before actions are taken\n$g_s$: The number of days in <u>a week</u>, susceptible persons go out [day]  "},{"metadata":{},"cell_type":"markdown","source":"We can calculate weighted average of days with age composion of population."},{"metadata":{"trusted":true},"cell_type":"code","source":"df = out_df.copy()\ndf[\"Portion\"] = df[\"Except China\"]\nec_out_df = df.drop(population_dict.keys(), axis=1)\nec_out_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gs_before = (ec_out_df[[\"School\", \"Office\", \"Others\"]].sum(axis=1) * ec_out_df[\"Portion\"]).sum()\ngs_before","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### $g_s$ value AFTER actions are taken\nIf all schools and offices will be closed, $g_s$ can be reduced. People will go out one day for other reasons instead of going to school/office."},{"metadata":{"trusted":true},"cell_type":"code","source":"df = ec_out_df.copy()\ndf[\"School\"] = 0\ndf[\"Office\"] = 0\ndf.loc[df.index[1:9], \"Others\"] += 1\ngs_after = (df[[\"School\", \"Office\", \"Others\"]].sum(axis=1) * df[\"Portion\"]).sum()\ngs_after","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Impact of actions on $\\beta_1$\nActions to take since today:  \nAll schools and offices will be closed.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"beta1_after = beta1_before * (gs_after / gs_before)\nbeta1_after / beta1_before","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Predict the future: with actions since today\nThere is a delay between the time point of starting actions and that of appearing the effect. Because I is the main variable, the length of delay can be estimated as sum of latent period and waiting time for confirmation. This value [day] was calculated in \"The number of exposed cases and waiting cases\" section."},{"metadata":{"trusted":true},"cell_type":"code","source":"latent_waiting_day","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"first_model, info_dict, param_dict = sewirf_estimator.info()\ninfo_dict[\"name\"] = \"Except China\"\nchanged_param_dict = param_dict.copy()\nchanged_param_dict[\"rho1\"] = param_dict[\"rho1\"] * beta1_after / beta1_before\ndf = pd.DataFrame.from_dict(\n    {\"No actions\": param_dict, \"With actions\": changed_param_dict},\n    orient=\"index\"\n)\ndf = df.loc[:, [\"rho1\", \"rho2\", \"rho3\", \"theta\", \"kappa\", \"sigma\"]]\ndf[\"R0\"] = df.apply(lambda x: first_model(**x.to_dict()).calc_r0(), axis=1)\ndf[\"tau\"] = info_dict[\"tau\"]\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicter = Predicter(**info_dict)\npredicter.add(SEWIRF, end_day_n=None, count_from_last=False, vline=False, **param_dict)\npredicter.add(SEWIRF, end_day_n=latent_waiting_day, count_from_last=True, **param_dict)\npredicter.add(SEWIRF, end_day_n=30, count_from_last=True, **changed_param_dict)\npredicter.restore_graph(drop_cols=[\"Susceptible\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicter = Predicter(**info_dict)\npredicter.add(SEWIRF, end_day_n=None, count_from_last=False, vline=False, **param_dict)\npredicter.add(SEWIRF, end_day_n=latent_waiting_day, count_from_last=True, **param_dict)\npredicter.add(SEWIRF, end_day_n=800, count_from_last=False, **changed_param_dict)\npredicter.restore_graph(drop_cols=None)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The actions result in:  \nTotal number of confirmed cases was decreased.  \nPeak point of infected cases was delayed.   \nWe need to fight with the virus for longer period."},{"metadata":{},"cell_type":"markdown","source":"## Real factors of recovery rate $\\gamma$ and mortality rate $\\alpha_2$\nHere, let's reconsider I $\\overset{\\gamma}{\\longrightarrow}$ R and I $\\overset{\\alpha_2}{\\longrightarrow}$ F.  \nBecause balance of immunity (+effect of treatments) and virulence determines whether patients can recover or not, the formulas can be replaced with  \n\nI $\\overset{\\bar{h}}{\\longrightarrow}$ I$^\\star$ $\\overset{\\bar{s}}{\\longrightarrow}$ F$^\\star$ $\\overset{L^{-1}}{\\longrightarrow}$ F  \nI $\\overset{f_2}{\\longrightarrow}$ R$^\\star$ $\\overset{l^{-1}}{\\longrightarrow}$ R  \n\nI$^\\star$: Confirmed cases whose immune systems did not overcome virus multiplication, and <u>without</u> severe events  \nF$^\\star$: Confirmed cases whose immune systems did not overcome virus multiplication, and <u>with</u> severe events  \nR$^\\star$: Confirmed cases whose immune systems overcame virus multiplication or comfirmed cases whose severe events can be stopped"},{"metadata":{},"cell_type":"markdown","source":"Where $f_2 = 1 - \\bar{h}\\ \\bar{s}$  \n\n$\\bar{h}$: Rate of I whose immune systems does NOT overcame virus multiplication [-]  \n$\\bar{s}$: Rate of I$^\\star$ who have severe events, including respiratory failure  [-]  \n$L_i$: Inverse of F$^\\star$'s mortality rate for people $i$ years old [min]  \n$l_i$: Inverse of R$^\\star$'s mortality rate for people $i$ years old [min]  \n$P_i$: The number of people $i$ years old [-]  \n$N$: Total population  \n\n\\begin{align*}\n& \\alpha_2 = \\cfrac{\\bar{h}\\ \\bar{s}}{N} \\sum_{n=0}^{\\infty}\\cfrac{P_{i}}{L_i} \\\\\n    & \\gamma = \\cfrac{1 - \\bar{h}\\ \\bar{s}}{N} \\sum_{n=0}^{\\infty}\\cfrac{P_{i}}{l_i} \\\\\n\\end{align*}"},{"metadata":{},"cell_type":"markdown","source":"## $\\bar{h}$ and $\\bar{s}$ value before actions are taken\nWe assume that $\\bar{h}=0.5$ and $\\bar{s}=0.5$. **(Yes, we need remove this assumtions later!)**  \n**(Using population distribution data and case reports, $\\bar{h}\\ \\bar{s}$ and $1 - \\bar{h}\\ \\bar{s}$ can be calculated.)**"},{"metadata":{"trusted":true},"cell_type":"code","source":"gamma_before = param_dict[\"sigma\"] / info_dict[\"tau\"]\nalpha2_before = param_dict[\"kappa\"] / info_dict[\"tau\"]\n(gamma_before, alpha2_before)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"h_bar_before, s_bar_before = 0.5, 0.5","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## $\\bar{h}$ and $\\bar{s}$ value AFTER actions are taken\nAssumtions of new medicines:  \n\"Protease inhibitor\" inhibits virus multiplication. This will reduce $\\bar{h}$"},{"metadata":{"trusted":true},"cell_type":"code","source":"h_bar_after = 0.25\ns_bar_after = s_bar_before","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Impact on $\\gamma$ and $\\alpha_2$\nActions to take:  \nNew Protein inhibitor medicine was introduced."},{"metadata":{"trusted":true},"cell_type":"code","source":"gamma_after = gamma_before * (1 - h_bar_after * s_bar_after) / (1 - h_bar_before * s_bar_before)\ngamma_after","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"alpha2_after = alpha2_before * (h_bar_after * s_bar_after) / (h_bar_before * s_bar_before)\nalpha2_after","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Predict the future: with actions from the next month"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"first_model, info_dict, param_dict = sewirf_estimator.info()\ninfo_dict[\"name\"] = \"Except China\"\nchanged_param_dict = param_dict.copy()\nchanged_param_dict[\"sigma\"] = param_dict[\"sigma\"] * gamma_after / gamma_before\nchanged_param_dict[\"kappa\"] = param_dict[\"kappa\"] * alpha2_after / alpha2_before\ndf = pd.DataFrame.from_dict(\n    {\"No actions\": param_dict, \"With actions\": changed_param_dict},\n    orient=\"index\"\n)\ndf = df.loc[:, [\"rho1\", \"rho2\", \"rho3\", \"theta\", \"kappa\", \"sigma\"]]\ndf[\"R0\"] = df.apply(lambda x: first_model(**x.to_dict()).calc_r0(), axis=1)\ndf[\"tau\"] = info_dict[\"tau\"]\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicter = Predicter(**info_dict)\npredicter.add(SEWIRF, end_day_n=None, count_from_last=False, vline=False, **param_dict)\npredicter.add(SEWIRF, end_day_n=30, count_from_last=True, **param_dict)\npredicter.add(SEWIRF, end_day_n=30, count_from_last=True, **changed_param_dict)\npredicter.restore_graph(drop_cols=[\"Susceptible\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicter = Predicter(**info_dict)\npredicter.add(SEWIRF, end_day_n=None, count_from_last=False, vline=False, **param_dict)\npredicter.add(SEWIRF, end_day_n=30, count_from_last=True, **param_dict)\npredicter.add(SEWIRF, end_day_n=500, count_from_last=False, **changed_param_dict)\npredicter.restore_graph(drop_cols=None)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The actions result in:  \nTotal numbers of confirmed/deaths cases were decreased."},{"metadata":{},"cell_type":"markdown","source":"## If 10,000,000/day are vaccinated (SIR-FV model) since today\nWe will predict the numbers of cases in the assumption that 10,000,000 persons will be vacctinated in one day until there are susceptible people.  \n$\\frac{\\mathrm{d}x}{\\mathrm{d}t}= - \\rho x y - \\omega$  \n$\\frac{\\mathrm{d}y}{\\mathrm{d}t}= \\rho (1-\\theta) x y - (\\sigma + \\kappa) y$  \n$\\frac{\\mathrm{d}z}{\\mathrm{d}t}= \\sigma y$  \n$\\frac{\\mathrm{d}w}{\\mathrm{d}t}= \\rho \\theta x y + \\kappa y$  \nWhere $\\omega_{(x>0)}=\\frac{10,000,000}{N}$ and $N$ is the total population.\n\nReproduction number can be defined as  \n$R_0 = \\rho (1 - \\theta) (\\sigma + \\kappa)^{-1}$"},{"metadata":{"trusted":true},"cell_type":"code","source":"first_model, info_dict, param_dict = sirf_estimator.info()\nchanged_param_dict = param_dict.copy()\nchanged_param_dict[\"n\"] = population_dict[\"Global\"] - population_dict[\"China\"]\nchanged_param_dict[\"v_per_day\"] = 10000000\npredicter = Predicter(**info_dict)\npredicter.add(SIRF, end_day_n=None, count_from_last=False, **param_dict)\npredicter.add(SIRFV, end_day_n=700, count_from_last=False, **changed_param_dict)\npredicter.restore_graph(drop_cols=None)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Scenario analysis in Italy\nIn this section, we will perform scenario analysis using data in Italy."},{"metadata":{},"cell_type":"markdown","source":"## Trend analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"show_trend(ncov_df, variable=\"Confirmed\", places=[(\"Italy\", None)])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We will use the records from 23Feb2020.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"it_start = \"23Feb2020\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_, it_df = create_target_df(\n    ncov_df, population_dict[\"Italy\"], places=[(\"Italy\", None)], start_date=it_start\n)\nline_plot(it_df.set_index(\"T\")[data_cols], f\"US: without Susceptible after {it_start}\", math_scale=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Estimate parameters of SIR-F model"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nit_sirf_estimator = Estimator(\n    SIRF, ncov_df, population_dict[\"Italy\"], name=\"Italy\", places=[(\"Italy\", None)],\n    start_date=it_start\n)\nit_sirf_dict = it_sirf_estimator.run()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"it_sirf_estimator.compare_graph()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Calculate $\\rho_2$ and $\\rho_3$\nTo estimate $\\rho_2=\\tau \\beta_2$ and $\\rho_3=\\tau \\beta_3$, we first calculate median value of latent period $\\overline{L_E}$ and waiting time for confirmation $\\overline{L_W}$ using linelist.  \n\n$\\beta_2$: Inverse of latent period [1/min]  \n$\\beta_3$: Inverse of waiting time for confirmation [1/min]  "},{"metadata":{"trusted":true},"cell_type":"code","source":"select_area(linelist_df, places=[(\"Italy\", None)], group=None)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Because the number of records in Italy is small, we will not use linelist data.**"},{"metadata":{},"cell_type":"markdown","source":"## Estimate parameters of SEWIR-F model"},{"metadata":{"trusted":true},"cell_type":"code","source":"_, info_dict, param_dict = it_sirf_estimator.info()\nparam_dict.pop(\"rho\")\nparam_dict[\"tau\"] = info_dict[\"tau\"]\nparam_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nit_estimator = Estimator(\n    SEWIRF, ncov_df, population_dict[\"Italy\"], name=\"Italy\", places=[(\"Italy\", None)],\n    start_date=it_start,\n    **param_dict\n)\nit_dict = it_estimator.run(700)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame.from_dict({\"SIR-F\": it_sirf_dict, \"SEWIR-F\": it_dict}, orient=\"index\").fillna(\"-\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"it_estimator.compare_graph()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Prediction with SEWIR-F model"},{"metadata":{"trusted":true},"cell_type":"code","source":"first_model, info_dict, param_dict = it_estimator.info()\npd.DataFrame.from_dict({\"No actions\": param_dict}, orient=\"index\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicter = Predicter(**info_dict)\npredicter.add(first_model, end_day_n=None, count_from_last=False, **param_dict)\npredicter.restore_graph(drop_cols=[\"Susceptible\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicter = Predicter(**info_dict)\npredicter.add(first_model, end_day_n=None, count_from_last=False, vline=False, **param_dict)\npredicter.add(first_model, end_day_n=30, count_from_last=True, **param_dict)\npredicter.restore_graph(drop_cols=[\"Susceptible\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicter = Predicter(**info_dict)\npredicter.add(first_model, end_day_n=300, count_from_last=False, **param_dict)\npredicter.restore_graph(drop_cols=None)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Effect of lockdown\nAcording to first report of [COVID-19 Mobility Monitoring project](https://covid19mm.github.io/) on 13Mar2020, the government of Italy declared a national lockdown on 09Mar2020 and all peole are asked to remain home. This resulted in average reduction of potential encounters of 19% during week 3 (from 07Mar2020 to 10Mar2020).  \n**Here, we will predict the effect of lockdown on 13Mar2020 with assumtion that the effect will be shown on 01Apr2020.**"},{"metadata":{},"cell_type":"markdown","source":"### How many days we have until the day the effect will be shown?"},{"metadata":{"trusted":true},"cell_type":"code","source":"lockdown_delay = int((datetime.strptime(\"01Apr2020\", \"%d%b%Y\") - datetime.today()).total_seconds() / 60 / 60 / 24)\nlockdown_delay","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Real factors of $\\beta_1$\n\nThe parameter in the math model:  \n$\\rho_1 = \\tau \\beta_1$  \n$\\beta_1 = \\cfrac{g_s g_i (1-q) v (1-m)^2 (1-w_e)^{w_n} e^{-(h_{1}+h_{2})} c \\delta}{49}$ [1/min]\n\nReal factors:  \n$g_s$: <u>The number of days in a week susceptible persons go out</u> [day]  \n$g_i$: The number of days in a week currently infected (confirmed) but un-quarantined persons go out [day]  \n$q$: Quarantine rate of currently infected (confirmed) patients [-]  \n$v$: Probability of virus existance in a droplet [-]  \n$m$: Rate of persons wearing masks effectively (depends logistically on supply of masks) [-]  \n$w_e$: Virus reduction effect of washing hands [-]  \n$w_n$: The number of times people washes their hands before touching their own faces after go out [-]  \n$h_1$: Health condition (active rate of cellular immunity factors) of susceptible and contacted persons [-]  \n$h_2$: Health condition (active rate of humoral immunity factors) of susceptible and contacted persons [-]  \n$c$: <u>The number of contacts between susceptible persons and patients while on the go in a minute (depends on population density)</u> [1/min]  \n$\\delta$:The product of unknown real factors [-]  \n\n"},{"metadata":{},"cell_type":"markdown","source":"### Value of real factors of $\\beta_1$ before/after the national lockdown\nA national lockdown will effect on $g_s$ and $c$."},{"metadata":{},"cell_type":"markdown","source":"### $g_s$ before the lockdown\nWe will estimate average number peple go out using @marcoferrante estimation table and population pyramid data.\nIt is necessary to replace the population pyramid data for Italy because the situation is different from the average data."},{"metadata":{"trusted":true},"cell_type":"code","source":"df = out_df.copy()\ndf[\"Portion\"] = df[\"Italy\"]\nit_out_df = df.drop(population_dict.keys(), axis=1)\nit_out_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gs_before = (it_out_df[[\"School\", \"Office\", \"Others\"]].sum(axis=1) * it_out_df[\"Portion\"]).sum()\ngs_before","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Estimation of $g_s$ after the lockdown is here.  \nThis is a rough estimate, and we need detailed information."},{"metadata":{"trusted":true},"cell_type":"code","source":"df = it_out_df.copy()\ndf[\"School\"] = 0\ndf.loc[df[\"Office\"] > 0, \"Office\"] = 0.5\ndf.loc[df[\"Others\"] > 0, \"Others\"] = 0.6\nit_out_after_df = df.copy()\nit_out_after_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gs_after = (it_out_after_df[[\"School\", \"Office\", \"Others\"]].sum(axis=1) * it_out_after_df[\"Portion\"]).sum()\ngs_after","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Acccoring the report, we assume average reduction of potential encounters of 19%."},{"metadata":{"trusted":true},"cell_type":"code","source":"c_before, c_after = 1.0, 0.81","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Effect of the lockdown on $\\rho_1$"},{"metadata":{"trusted":true},"cell_type":"code","source":"rho1_before = param_dict[\"rho1\"]\nrho1_after = rho1_before * (gs_after / gs_before) * (c_after / c_before)\n(rho1_before, rho1_after)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Predict the future with the national lockdown"},{"metadata":{"trusted":true},"cell_type":"code","source":"changed_param_dict = param_dict.copy()\nchanged_param_dict[\"rho1\"] = rho1_after\ndf = pd.DataFrame.from_dict(\n    {\"No actions\": param_dict, \"With actions\": changed_param_dict},\n    orient=\"index\"\n)\ndf[\"R0\"] = df.apply(lambda x: first_model(**x.to_dict()).calc_r0(), axis=1)\ndf[\"tau\"] = info_dict[\"tau\"]\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In a week,"},{"metadata":{"trusted":true},"cell_type":"code","source":"predicter = Predicter(**info_dict)\npredicter.add(SEWIRF, end_day_n=None, count_from_last=False, vline=False, **param_dict)\npredicter.add(SEWIRF, end_day_n=lockdown_delay, count_from_last=True, **param_dict)\npredicter.add(SEWIRF, end_day_n=7, count_from_last=True, **changed_param_dict)\npredicter.restore_graph(drop_cols=[\"Susceptible\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In 30 days,"},{"metadata":{"trusted":true},"cell_type":"code","source":"predicter = Predicter(**info_dict)\npredicter.add(SEWIRF, end_day_n=None, count_from_last=False, vline=False, **param_dict)\npredicter.add(SEWIRF, end_day_n=lockdown_delay, count_from_last=True, **param_dict)\npredicter.add(SEWIRF, end_day_n=30, count_from_last=True, **changed_param_dict)\npredicter.restore_graph(drop_cols=[\"Susceptible\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Values are here."},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"df = predicter.restore_df()\ndf.loc[datetime.today():, :].head(30).style.background_gradient(axis=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the long-term,"},{"metadata":{"trusted":true},"cell_type":"code","source":"predicter.restore_graph(drop_cols=[\"Susceptible\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicter = Predicter(**info_dict)\npredicter.add(SEWIRF, end_day_n=None, count_from_last=False, vline=False, **param_dict)\npredicter.add(SEWIRF, end_day_n=lockdown_delay, count_from_last=True, **param_dict)\npredicter.add(SEWIRF, end_day_n=1000, count_from_last=False, **changed_param_dict)\npredicter.restore_graph(drop_cols=None)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Time point of peak may be delayed."},{"metadata":{},"cell_type":"markdown","source":"## Effect of expected new medicines (Favipiravir, AVIGAN)\nNew medicines are necessary so that patients can recover more quicky from the disease. Drug repositioning strategy (i.e.finding effective candidates from library of existing drugs of different diseases) is used to develop the medicines of COVID-19. For example, Favipiravir (AVIGAN) is a candidate. Certainly, this medicine may lead many serious adverse reactions and it cannot be provided to expectant mothers [KEGG database AVIGAN](https://www.kegg.jp/medicus-bin/japic_med?japic_code=00066852) (Sorry, this is written in Japanese). However, it may help to save many thousand lives.  \n\n**We do not have information about its criteria to administrate and medicinal effect on COVID-19. We assume that fatal risk $\\bar{h}\\ \\bar{s}$ will be halved (0.50 $\\to$ 0.25) from 01May2020.**\n(The values may be different for each age group, but we assume they are constant now.)\n\nWhere  \n\\begin{align*}\n& \\kappa \\tau^{-1} = \\alpha_2 = \\cfrac{\\bar{h}\\ \\bar{s}}{N} \\sum_{n=0}^{\\infty}\\cfrac{P_{i}}{L_i} \\\\\n& \\sigma \\tau^{-1} = \\gamma = \\cfrac{1 - \\bar{h}\\ \\bar{s}}{N} \\sum_{n=0}^{\\infty}\\cfrac{P_{i}}{l_i} \\\\\n\\end{align*}\n\n$\\bar{h}$: Rate of I whose immune systems does NOT overcame virus multiplication [-]  \n$\\bar{s}$: Rate of I$^\\star$ who have severe events, including respiratory failure  [-]  \n$L_i$: Inverse of F$^\\star$'s mortality rate for people $i$ years old [min]  \n$l_i$: Inverse of R$^\\star$'s mortality rate for people $i$ years old [min]  \n$P_i$: The number of people $i$ years old [-]  \n$N$: Total population  \n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"med_delay = int((datetime.strptime(\"01May2020\", \"%d%b%Y\") - datetime.today()).total_seconds() / 60 / 60 / 24)\nmed_delay","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"med_changed_param_dict = changed_param_dict.copy()\nmed_changed_param_dict[\"kappa\"] = changed_param_dict[\"kappa\"] * 0.25 / 0.50\nmed_changed_param_dict[\"sigma\"] = changed_param_dict[\"sigma\"] * (1 - 0.25) / (1 - 0.50)\n_dict = {\n    \"No actions\": param_dict,\n    \"National lockdown\": changed_param_dict,\n    \"Lockdown + Medicine\": med_changed_param_dict\n}\ndf = pd.DataFrame.from_dict(_dict, orient=\"index\")\ndf[\"R0\"] = df.apply(lambda x: first_model(**x.to_dict()).calc_r0(), axis=1)\ndf[\"tau\"] = info_dict[\"tau\"]\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In three months,"},{"metadata":{"trusted":true},"cell_type":"code","source":"predicter = Predicter(**info_dict)\npredicter.add(SEWIRF, end_day_n=None, count_from_last=False, vline=False, **param_dict)\npredicter.add(SEWIRF, end_day_n=lockdown_delay, count_from_last=True, **param_dict)\npredicter.add(SEWIRF, end_day_n=30, count_from_last=True, **changed_param_dict)\npredicter.add(SEWIRF, end_day_n=30, count_from_last=True, **med_changed_param_dict)\npredicter.restore_graph(drop_cols=[\"Susceptible\"], y_integer=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Values are here,"},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"df = predicter.restore_df()\ndf.loc[datetime.today():, :].head(90).style.background_gradient(axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicter = Predicter(**info_dict)\npredicter.add(SEWIRF, end_day_n=None, count_from_last=False, vline=False, **param_dict)\npredicter.add(SEWIRF, end_day_n=lockdown_delay, count_from_last=True, **param_dict)\npredicter.add(SEWIRF, end_day_n=30, count_from_last=True, **changed_param_dict)\npredicter.add(SEWIRF, end_day_n=1000, count_from_last=False, **med_changed_param_dict)\npredicter.restore_graph(drop_cols=[\"Susceptible\"], y_integer=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c6031338-1749-4ecc-a8c7-86576a7abbf0","_cell_guid":"8a74f1df-afc5-47a1-8a81-e2cdeceea031","trusted":true},"cell_type":"markdown","source":"# Remarks and To-do list\nThank you for reading!  \nLisphilar from Japan"},{"metadata":{"_uuid":"e0ceec35-5eb1-414f-9cb6-cb7748390066","_cell_guid":"af54ab9a-c782-440f-bb76-3e98f3afaa5c","trusted":true},"cell_type":"markdown","source":"## Remarks"},{"metadata":{"_uuid":"d4f0eb10-dd97-438e-aba5-f22c1f56aa33","_cell_guid":"2884b79e-b763-4fc0-851d-31c7ba2e0f8d","trusted":true},"cell_type":"markdown","source":"Non-dimentional SIR/SIR-D/SIR-F model explained the total data except China. Predicted values with the parameters estimated by model fitting is under the assumption that no new actions will be taken. If no actions will be taken, almost all peaple may be infected by this disease...\n"},{"metadata":{"_uuid":"90bb86b4-507a-4954-89b6-52584ab29ed7","_cell_guid":"69e3168e-b0f9-40b0-8685-506a0e3d5422","trusted":true},"cell_type":"markdown","source":"If trend changes, including the effect of measures, are observed in \"Trend analysis\" section, we will need to replace the model to apply to the dataset after the change points. It is difficult to add another varible/parameter to the model because we can measure only 4 variables (confirmed, recovered, deaths, total population) now. To improve the accuracy, ODEs should be replaced."},{"metadata":{"_uuid":"6ca5a1be-3ab0-4525-b4f4-8b49c7eb174c","_cell_guid":"20c990eb-234b-4dc3-b31d-2b2addda5238","trusted":true},"cell_type":"markdown","source":"With the models, we predicted the effect of actions on the numbers of cases. New medicines and vaccines are expected, but, in initial state, we must make an effort to minimize effective contact rate $\\rho$ by quarantining/wearing of masks. This effort will reduce the number of infected cases directory."},{"metadata":{"_uuid":"927a2c31-f6b5-4689-bd0d-b085a96bd2f8","_cell_guid":"fbe17425-6495-4339-b738-625939145e61","trusted":true},"cell_type":"markdown","source":"## To-do list\n\n* Find out the root cause of unstable accuracy of estimation and improve Estimater class\n* Increase speed of the functions and classes. Estimater.run(), which uses Optuna and scipy.integrate.solve_ivp, is a key method, but time-consuming one.\n* Reconsider the ODEs of SIR-F model using new records\n* Find out the change points using case reports and news information, and feed-back to the model.\n* Discuss $R_0$ using the data of the other infectious diseases\n* Calculate the impact of preventive actions on the parameters of math models and find out effective preventive actions."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}